<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://your-docusaurus-test-site.com/blog</id>
    <title>机器学习小纵队 Blog</title>
    <updated>2025-06-16T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://your-docusaurus-test-site.com/blog"/>
    <subtitle>机器学习小纵队 Blog</subtitle>
    <icon>https://your-docusaurus-test-site.com/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[相关GAN及其SRGAN消融试验]]></title>
        <id>https://your-docusaurus-test-site.com/blog/12-相关GAN及其SRGAN消融试验</id>
        <link href="https://your-docusaurus-test-site.com/blog/12-相关GAN及其SRGAN消融试验"/>
        <updated>2025-06-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[本文将从三部分，即GAN模型的理论部分，代码（实践）部分及SRGAN的消融试验部分展开介绍]]></summary>
        <content type="html"><![CDATA[<p>本文将从三部分，即GAN模型的理论部分，代码（实践）部分及SRGAN的消融试验部分展开介绍</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-gangenerative-adversarial-network生成对抗网络">1. GAN（Generative Adversarial Network）生成对抗网络<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#1-gangenerative-adversarial-network%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C" class="hash-link" aria-label="Direct link to 1. GAN（Generative Adversarial Network）生成对抗网络" title="Direct link to 1. GAN（Generative Adversarial Network）生成对抗网络">​</a></h2>
<p>核心：由两个神经网络——生成器（Generator）和判别器（Discriminator）组成，通过博弈过程相互提升。
· 生成器：试图“伪造”以假乱真的数据。
· 判别器：判断输入是真实数据还是生成器伪造的。
· 训练目标：生成器希望骗过判别器，判别器希望准确识别真假。
本质上是一个最大最小问题：</p>
<div class="language-math codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-math codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">\min_G \max_D \ \mathbb{E}_{x \sim p_{\text{data}}} \left[ \log D(x) \right] + \mathbb{E}_{z \sim p_z} \left[ \log \left(1 - D(G(z)) \right) \right]</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-cganconditional-gan条件生成对抗网络">2. cGAN（Conditional GAN）条件生成对抗网络<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#2-cganconditional-gan%E6%9D%A1%E4%BB%B6%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C" class="hash-link" aria-label="Direct link to 2. cGAN（Conditional GAN）条件生成对抗网络" title="Direct link to 2. cGAN（Conditional GAN）条件生成对抗网络">​</a></h2>
<p>核心：在GAN的基础上，引入“条件”信息（如标签、图像、文本等）
· 生成器和判别器都接收条件变量
· G（z，y）：在条件 y 下生成图像
· D（x，y）：判断图像是否为在条件 y 下真实的
用途：图像翻译（如黑白图像上色）、语义图生成图像、文本生成图像
目标函数：</p>
<div class="language-math codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-math codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">\min_G \max_D \ \mathbb{E}_{x,y \sim p_{\text{data}}} \left[ \log D(x|y) \right] + \mathbb{E}_{z \sim p_z} \left[ \log \left(1 - D(G(z|y)) \right) \right]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-srgan">3. SRGAN<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#3-srgan" class="hash-link" aria-label="Direct link to 3. SRGAN" title="Direct link to 3. SRGAN">​</a></h2>
<p>目的：图像超分辨率，即将低分辨率图像（LR）还原成高分辨率图像（HR）
· 生成器结构：使用残差网络（ResNet）进行细节重建。
· 判别器：区分生成的高分图像和真实高分图像。
损失函数包含：
· 内容损失（如 MSE 或感知损失）；
· 对抗损失（判别器输出）
· 感知损失（Perceptual Loss）：在 VGG 网络的高层 feature 上计算差异，更贴近人类视觉感受</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-esrgan">4. ESRGAN<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#4-esrgan" class="hash-link" aria-label="Direct link to 4. ESRGAN" title="Direct link to 4. ESRGAN">​</a></h2>
<p>基于SRGAN，具有如下优势：</p>
<ol>
<li>Residual-in-Residual Dense Block (RRDB)：替换原 SRGAN 的残差块，结构更深，信息流更丰富。</li>
<li>对抗损失改进：采用 Relativistic average GAN（RaGAN），即判断“生成图是否比真实图更假”，而不是简单判断真假。</li>
<li>感知损失优化：使用未归一化的 VGG 特征图，避免图像过光滑。</li>
<li>训练技巧：使用多阶段训练，包括先训练内容损失，再加入对抗训练</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="总结理论部分">总结（理论部分）<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#%E6%80%BB%E7%BB%93%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86" class="hash-link" aria-label="Direct link to 总结（理论部分）" title="Direct link to 总结（理论部分）">​</a></h2>
<table><thead><tr><th>名称</th><th>全称</th><th>类型</th><th>特点概述</th></tr></thead><tbody><tr><td>GAN</td><td>Generative Adversarial Net</td><td>无监督生成</td><td>对抗生成图像</td></tr><tr><td>cGAN</td><td>Conditional GAN</td><td>条件生成</td><td>加入标签或条件进行控制</td></tr><tr><td>SRGAN</td><td>Super-Resolution GAN</td><td>图像超分辨率</td><td>使用感知损失，生成自然高分图像</td></tr><tr><td>ESRGAN</td><td>Enhanced SRGAN</td><td>图像超分辨率</td><td>加强网络结构和损失函数，细节更佳</td></tr></tbody></table>
<p><strong>在后文的试验中，原始代码与数据集皆存放在GitHub仓库：<a href="https://github.com/zqqqqqqj1110/GAN_WB" target="_blank" rel="noopener noreferrer">https://github.com/zqqqqqqj1110/GAN_WB</a></strong></p>
<h1>GAN对抗神经网络及其变种（试验部分）</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-cgan">1. cGAN<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#1-cgan" class="hash-link" aria-label="Direct link to 1. cGAN" title="Direct link to 1. cGAN">​</a></h2>
<p>本文以cGAN作为baseline，后续的gan变种模型皆由该部分代码变换而来，因此在这部分会讲的较为全面一些，后文可能会省略</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="11-安装需要的包与环境">1.1 安装需要的包与环境<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#11-%E5%AE%89%E8%A3%85%E9%9C%80%E8%A6%81%E7%9A%84%E5%8C%85%E4%B8%8E%E7%8E%AF%E5%A2%83" class="hash-link" aria-label="Direct link to 1.1 安装需要的包与环境" title="Direct link to 1.1 安装需要的包与环境">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch.nn.functional as F</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch.optim as optim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from torch.utils.data import Dataset, DataLoader</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from skimage.metrics import peak_signal_noise_ratio, structural_similarity</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import matplotlib.pyplot as plt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from pytorch_msssim import ms_ssim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(device)</span><br></span></code></pre></div></div>
<p>作者使用的是MacOS，因此使用了mps，如果是cuda的话直接换成“cuda”即可，配置环境部分（gpu环境）可转到我的个人博客处查阅（或者在这更，懒了，小鸽一下^_^）</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="12-数据预处理">1.2 数据预处理<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#12-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" class="hash-link" aria-label="Direct link to 1.2 数据预处理" title="Direct link to 1.2 数据预处理">​</a></h3>
<p>首先需要加载原始的数据集，接着在低分辨率下生成数据（下采样）与保存（通过双线性插值的方法），最后计算mean，std等标准指标（都是后面需要用到的，为了计算指标，不如手动自己计算一下）</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># === 1. 加载原始 HR 数据 ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_train = np.load("seasonal_split/HR_data_train_tm_Summer.npy")[:200]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_valid = np.load("seasonal_split/HR_data_valid_tm_Summer.npy")[:200]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_test = np.load("seasonal_split/HR_data_test_tm_Summer.npy")[:200]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 2. 生成 LR 数据（双线性插值至 16×16） ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def downsample(hr_array, scale=4):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tensor = torch.tensor(hr_array, dtype=torch.float32)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return F.interpolate(tensor, scale_factor=1/scale, mode="bilinear", align_corners=False).numpy()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lr_train = downsample(hr_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lr_valid = downsample(hr_valid)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lr_test = downsample(hr_test)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 3. 保存为 .npy 文件 ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/HR_data_train_40.npy", hr_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/LR_data_train_40.npy", lr_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/HR_data_valid_40.npy", hr_valid)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/LR_data_valid_40.npy", lr_valid)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/HR_data_test_40.npy", hr_test)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/LR_data_test_40.npy", lr_test)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 4. mean和std===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mean = np.mean(hr_train, axis=(0, 2, 3))[:, None, None]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">std = np.std(hr_train, axis=(0, 2, 3))[:, None, None]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/mean_40.npy", mean)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/std_40.npy", std)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 每个通道的 min 和 max（例如 2 个通道）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_min = hr_train.min(axis=(0, 2, 3))  # shape: (2,)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_max = hr_train.max(axis=(0, 2, 3))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 保存为 .npy 文件，后续评估使用</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/min_40.npy", hr_min.astype(np.float32))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("tm/max_40.npy", hr_max.astype(np.float32))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print("完成：生成 LR/HR 切片、保存归一化参数，包括 test")</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="13-自定义数据集类">1.3 自定义数据集类<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#13-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB" class="hash-link" aria-label="Direct link to 1.3 自定义数据集类" title="Direct link to 1.3 自定义数据集类">​</a></h3>
<p>为了后续方便训练，自定义数据集类，主要是为了变形等操作。最终目的是对每张图进行归一化（标准化）并用于 DataLoader 加载训练/验证数据</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">class WeatherDataset(Dataset):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, lr_path, hr_path, mean_path, std_path):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.lr = np.load(lr_path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.hr = np.load(hr_path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.mean = np.load(mean_path).reshape(2, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.std = np.load(std_path).reshape(2, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __len__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return len(self.lr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __getitem__(self, idx):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lr = (self.lr[idx] - self.mean) / self.std</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        hr = (self.hr[idx] - self.mean) / self.std</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return torch.tensor(lr, dtype=torch.float32), torch.tensor(hr, dtype=torch.float32)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="14-定义生成器">1.4 定义生成器<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#14-%E5%AE%9A%E4%B9%89%E7%94%9F%E6%88%90%E5%99%A8" class="hash-link" aria-label="Direct link to 1.4 定义生成器" title="Direct link to 1.4 定义生成器">​</a></h3>
<p>定义cGAN等生成器部分，编码器通过两层卷积和 LeakyReLU 将输入图像从 16×16 压缩至 4×4，用于提取深层特征；解码器则通过四层反卷积（ConvTranspose）逐步上采样回 64×64，同时使用 BatchNorm 和 ReLU 激活保持稳定性和非线性表达能力。最终一层使用 Tanh 激活输出高分辨率图像</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">class GeneratorUNet(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=2, out_channels=2, features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.encoder = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(in_channels, features, 4, 2, 1),  # 16×16 → 8×8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 2, 4, 2, 1),  # 8×8 → 4×4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features * 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.decoder = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ConvTranspose2d(features * 2, features, 4, 2, 1),  # 4×4 → 8×8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ConvTranspose2d(features, features, 4, 2, 1),  # 8×8 → 16×16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ConvTranspose2d(features, features, 4, 2, 1),  # 16×16 → 32×32</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.ConvTranspose2d(features, out_channels, 4, 2, 1),  # 32×32 → 64×64</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Tanh()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.decoder(self.encoder(x))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="15-定义判别器">1.5 定义判别器<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#15-%E5%AE%9A%E4%B9%89%E5%88%A4%E5%88%AB%E5%99%A8" class="hash-link" aria-label="Direct link to 1.5 定义判别器" title="Direct link to 1.5 定义判别器">​</a></h3>
<p>使用多个卷积层对输入图像局部区域进行真实性判别，输入为上采样后的 LR 图像与真实/生成 HR 图像的拼接结果。网络逐层下采样并输出一个 7×7 的判别图，对图像中各个局部 patch 给出是否真实的预测评分</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class Discriminator(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=4, features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.model = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(in_channels, features, 4, 2, 1),  # (B, 64, 32, 32)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 2, 4, 2, 1),  # (B, 128, 16, 16)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features * 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features * 2, features * 4, 4, 2, 1),  # (B, 256, 8, 8)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features * 4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features * 4, 1, 4, 1, 1),  # (B, 1, 7, 7) =&gt; PatchGAN 输出</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Sigmoid()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, lr_up, hr_or_fake):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Ensure both inputs are [B, 2, 64, 64]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if lr_up.shape[-2:] != hr_or_fake.shape[-2:]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            raise ValueError(f"Shape mismatch: lr_up={lr_up.shape}, hr={hr_or_fake.shape}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = torch.cat([lr_up, hr_or_fake], dim=1)  # =&gt; [B, 4, H, W]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.model(x)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="16-计算指标">1.6 计算指标<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#16-%E8%AE%A1%E7%AE%97%E6%8C%87%E6%A0%87" class="hash-link" aria-label="Direct link to 1.6 计算指标" title="Direct link to 1.6 计算指标">​</a></h3>
<p>本文以SSIM，PSNR为例，对模型进行评估，需要注意的是归一化不应该是z-score，而是应该使用max-min归一化（吃过一次亏）</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">from skimage.metrics import peak_signal_noise_ratio, structural_similarity</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch.nn.functional as F</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def compute_psnr_ssim(pred, target):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 转换为 numpy 格式，shape: (N, H, W, C)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pred = pred.detach().cpu().numpy().transpose(0, 2, 3, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    target = target.detach().cpu().numpy().transpose(0, 2, 3, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_range = max(target.max(), pred.max()) - min(target.min(), pred.min())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    psnr_total, ssim_total = 0, 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for p, t in zip(pred, target):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        psnr_total += peak_signal_noise_ratio(t, p, data_range=data_range)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ssim_total += structural_similarity(t, p, channel_axis=-1, data_range=data_range)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return psnr_total / len(pred), ssim_total / len(pred)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def compute_rmse(pred, target):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return torch.sqrt(torch.mean((pred - target) ** 2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def compute_mae(pred, target):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return torch.mean(torch.abs(pred - target))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 添加 SSIM Loss ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def ssim_loss(pred, target, C1=0.01**2, C2=0.03**2):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mu_x = F.avg_pool2d(pred, 3, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mu_y = F.avg_pool2d(target, 3, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sigma_x = F.avg_pool2d(pred ** 2, 3, 1, 1) - mu_x ** 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sigma_y = F.avg_pool2d(target ** 2, 3, 1, 1) - mu_y ** 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sigma_xy = F.avg_pool2d(pred * target, 3, 1, 1) - mu_x * mu_y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ssim_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ssim_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ssim_map = ssim_n / (ssim_d + 1e-8)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return 1 - ssim_map.mean()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 加载 min/max</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_min = np.load("tm/min_40.npy")[:, None, None]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hr_max = np.load("tm/max_40.npy")[:, None, None]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def minmax_scale(tensor):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 缩放到 0~1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return (tensor - torch.tensor(hr_min, dtype=torch.float32).to(tensor.device)) / \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           (torch.tensor(hr_max - hr_min, dtype=torch.float32).to(tensor.device))</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="17-加载数据集准备训练">1.7 加载数据集，准备训练<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#17-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87%E8%AE%AD%E7%BB%83" class="hash-link" aria-label="Direct link to 1.7 加载数据集，准备训练" title="Direct link to 1.7 加载数据集，准备训练">​</a></h3>
<p>batch size为将n个样本为一组（一个批次）读取数据.将之前的训练集，测试集与评估集上传到数据类并加载，准备训练。需要注意的是batch size越大，对gpu的负担也越大，但是同时训练到的数据也越多</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">train_set = WeatherDataset(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/LR_data_train_40.npy", "tm/HR_data_train_40.npy",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/mean_40.npy", "tm/std_40.npy"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val_set = WeatherDataset(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/LR_data_valid_40.npy", "tm/HR_data_valid_40.npy",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/mean_40.npy", "tm/std_40.npy"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_set = WeatherDataset(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/LR_data_test_40.npy", "tm/HR_data_test_40.npy",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/mean_40.npy", "tm/std_40.npy"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_loader = DataLoader(test_set, batch_size=32, shuffle=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_loader = DataLoader(train_set, batch_size=32, shuffle=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val_loader = DataLoader(val_set, batch_size=32, shuffle=False)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="18-模型训练">1.8 模型训练<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#18-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" class="hash-link" aria-label="Direct link to 1.8 模型训练" title="Direct link to 1.8 模型训练">​</a></h3>
<p>首先先对模型进行初始化，最后一句print为形状，如果形状不对后续训练必失败。实例化生成器和判别器并送到设备（MPS 或 CPU）；接着定义损失函数，MSELoss 用于像素级内容损失，BCELoss 用于 GAN 判别器对抗损失；最后定义优化器，使用ADAM进行优化并将学习率调为1e-4</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># === 6. Model Initialization ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">G = GeneratorUNet().to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">D = Discriminator().to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">criterion_GAN = nn.BCEWithLogitsLoss()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">criterion_L1 = nn.L1Loss()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">opt_G = torch.optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.999), weight_decay=1e-4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">opt_D = torch.optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.999), weight_decay=1e-4)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dummy_input = torch.randn(1, 2, 16, 16).to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dummy_output = G(dummy_input)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f"G output shape: {dummy_output.shape}")  # 应该是 [1, 2, 64, 64]</span><br></span></code></pre></div></div>
<p>准备好了之后，最后开始进行模型的训练与保存，训练时可以将每一轮epoch的指标都保存在数组中，方便后续画图；还需要注意在训练前准备标签构造，为对抗训练准备真假标签（用于 BCELoss）且判别器输出是 6×6 patch 的预测，匹配标签形状。</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">num_epochs = 200</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_psnrs, train_ssims, train_rmses, train_maes = [], [], [], []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val_psnrs, val_ssims, val_rmses, val_maes = [], [], [], []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for epoch in range(num_epochs):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    G.train()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for lr, hr in train_loader:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lr, hr = lr.to(device), hr.to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # === Forward Generator ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fake = G(lr).to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lr_up = F.interpolate(lr, size=hr.shape[-2:], mode="bilinear", align_corners=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # === Train Discriminator ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        D_real = D(lr_up, hr).to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        D_fake = D(lr_up, fake.detach()).to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_D = (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            criterion_GAN(D_real, torch.ones_like(D_real)) +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            criterion_GAN(D_fake, torch.zeros_like(D_fake))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ) * 0.5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        opt_D.zero_grad()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_D.backward()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        opt_D.step()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # === Train Generator ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred = D(lr_up, fake)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_ssim = ssim_loss(fake, hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_l1 = criterion_L1(fake, hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_gan = criterion_GAN(pred, torch.ones_like(pred))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_G = 0.01 * loss_gan + 1.0 * loss_ssim + 1.0 * loss_l1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        opt_G.zero_grad()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss_G.backward()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        opt_G.step()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_pred = G(lr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_pred = F.interpolate(train_pred, size=hr.shape[-2:], mode="bilinear", align_corners=False).to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 评估</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_pred_mm = minmax_scale(train_pred)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    hr_mm = minmax_scale(hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    psnr_train, ssim_train = compute_psnr_ssim(train_pred, hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rmse_train = compute_rmse(train_pred_mm, hr_mm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mae_train = compute_mae(train_pred_mm, hr_mm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # 添加保存</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_psnrs.append(psnr_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_ssims.append(ssim_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_rmses.append(rmse_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_maes.append(mae_train)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    G.eval()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_lr, val_hr = next(iter(val_loader))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_lr, val_hr = val_lr.to(device), val_hr.to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred_hr = G(val_lr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred_hr = F.interpolate(pred_hr, size=val_hr.shape[-2:], mode="bilinear", align_corners=False).to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 计算指标</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred_val_mm = minmax_scale(pred_hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_hr_mm = minmax_scale(val_hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        psnr_val, ssim_val = compute_psnr_ssim(pred_hr, val_hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rmse_val = compute_rmse(pred_val_mm, val_hr_mm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        mae_val = compute_mae(pred_val_mm, val_hr_mm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 添加保存</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_psnrs.append(psnr_val)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_ssims.append(ssim_val)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_rmses.append(rmse_val)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val_maes.append(mae_val)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # === Print summary ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f"Epoch {epoch+1}: "</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          f"Train PSNR={psnr_train:.2f}, SSIM={ssim_train:.4f}, RMSE={rmse_train:.4f}, MAE={mae_train:.4f} | "</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          f"Valid PSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}, RMSE={rmse_val:.4f}, MAE={mae_val:.4f}")</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="19-模型验证">1.9 模型验证<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#19-%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81" class="hash-link" aria-label="Direct link to 1.9 模型验证" title="Direct link to 1.9 模型验证">​</a></h3>
<p>训练完了之后对保存好了的模型进行test验证，查看评估指标的表现</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import matplotlib.pyplot as plt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from torch.utils.data import DataLoader</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 1. 加载测试集 ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_set = WeatherDataset(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/LR_data_test_40.npy", "tm/HR_data_test_40.npy",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "tm/mean_40.npy", "tm/std_40.npy"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_loader = DataLoader(test_set, batch_size=8, shuffle=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 2. 在测试集上评估模型 ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">G.eval()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_psnrs, test_ssims, test_rmses, test_maes = [], [], [], []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">images_to_show = []  # 原图、真实图、预测图（反归一化后）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 反归一化函数</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mean = np.load("tm/mean_40.npy")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">std = np.load("tm/std_40.npy")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def denormalize(tensor):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return tensor * torch.tensor(std).to(tensor.device) + torch.tensor(mean).to(tensor.device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">with torch.no_grad():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for test_lr, test_hr in test_loader:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        test_lr, test_hr = test_lr.to(device), test_hr.to(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred_test = G(test_lr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred_test = F.interpolate(pred_test, size=test_hr.shape[-2:], mode="bilinear", align_corners=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 计算指标（归一化下）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pred_mm = minmax_scale(pred_test)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        hr_mm = minmax_scale(test_hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        psnr, ssim = compute_psnr_ssim(pred_test, test_hr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rmse = compute_rmse(pred_mm, hr_mm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        mae = compute_mae(pred_mm, hr_mm)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        test_psnrs.append(psnr)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        test_ssims.append(ssim)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        test_rmses.append(rmse.cpu().item())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        test_maes.append(mae.cpu().item())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 可视化：选取前1张图，反归一化</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for i in range(1):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            lr_img = F.interpolate(test_lr[i:i+1], size=(64, 64), mode="bilinear", align_corners=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            images_to_show.append((</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                denormalize(lr_img[0].cpu()),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                denormalize(test_hr[i].cpu()),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                denormalize(pred_test[i].cpu())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># === 3. 打印测试集平均指标 ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f"Test Set Evaluation cGAN Winter:")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f"PSNR: {np.mean(test_psnrs):.2f}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f"SSIM: {np.mean(test_ssims):.4f}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f"RMSE: {np.mean(test_rmses):.4f}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f"MAE: {np.mean(test_maes):.4f}")</span><br></span></code></pre></div></div>
<hr>
<p><strong>常用指标计算公式</strong></p>
<ol>
<li>PSNR（峰值信噪比）</li>
</ol>
<div class="language-math codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-math codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">\text{PSNR} = 10 \cdot \log_{10} \left( \frac{MAX^2}{\text{MSE}} \right)</span><br></span></code></pre></div></div>
<hr>
<ol start="2">
<li>SSIM（结构相似性）</li>
</ol>
<div class="language-math codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-math codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">\text{SSIM}(x, y) = \frac{(2\mu_x \mu_y + C_1)(2\sigma_{xy} + C_2)}{(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 + C_2)}</span><br></span></code></pre></div></div>
<hr>
<ol start="3">
<li>RMSE（均方根误差）</li>
</ol>
<div class="language-math codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-math codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - y_i)^2}</span><br></span></code></pre></div></div>
<hr>
<ol start="4">
<li>MAE（平均绝对误差）</li>
</ol>
<div class="language-math codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-math codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |x_i - y_i|</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="110-保存">1.10 保存<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#110-%E4%BF%9D%E5%AD%98" class="hash-link" aria-label="Direct link to 1.10 保存" title="Direct link to 1.10 保存">​</a></h3>
<p>这部分就不多说了，提供一下评估指标的保存方式，接着想可视化等等皆可</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 将数组保存为 .npy 文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_ssim_train.npy", train_ssims)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_psnr_train.npy", train_psnrs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_ssim_valid.npy", val_ssims)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_psnr_valid.npy", val_psnrs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print("✅ 已保存为 1_ssim_train.npy, 1_psnr_train.npy, 1_ssim_valid.npy, 1_psnr_valid.npy")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 确保每个 tensor 都通过 .detach() 断开计算图，之后转移到 CPU 并转换为 NumPy 数组</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_maes_cpu = [mae.detach().cpu().numpy() for mae in train_maes]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_rmses_cpu = [rmse.detach().cpu().numpy() for rmse in train_rmses]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">valid_maes_cpu = [mae.detach().cpu().numpy() for mae in val_maes]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">valid_rmses_cpu = [rmse.detach().cpu().numpy() for rmse in val_rmses]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 保存为 .npy 文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_mae_train.npy", train_maes_cpu)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_rmes_train.npy", train_rmses_cpu)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_mae_valid.npy", valid_maes_cpu)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">np.save("1_rmes_valid.npy", valid_rmses_cpu)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># .npy 文件的列表</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">files = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "1_mae_train.npy", "1_mae_valid.npy", </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "1_psnr_train.npy", "1_psnr_valid.npy",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "1_rmes_train.npy", "1_rmes_valid.npy",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "1_ssim_train.npy", "1_ssim_valid.npy"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 创建一个字典来存储数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data_dict = {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 加载每个 .npy 文件并存入字典</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for file in files:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_dict[file] = np.load(file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 将字典转换为 pandas DataFrame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df = pd.DataFrame(data_dict)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 将 DataFrame 保存为 CSV 文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df.to_csv("cGAN_data_Winter.csv", index=False)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-srgan">2. SRGAN<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#2-srgan" class="hash-link" aria-label="Direct link to 2. SRGAN" title="Direct link to 2. SRGAN">​</a></h2>
<p>大部分可类比过来，具体就去看原代码，这里就讲一些不一样的部分，比如说生成器与判别器</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-生成器模型-srresnetgenerator">2.1 生成器模型 SRResNetGenerator<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#21-%E7%94%9F%E6%88%90%E5%99%A8%E6%A8%A1%E5%9E%8B-srresnetgenerator" class="hash-link" aria-label="Direct link to 2.1 生成器模型 SRResNetGenerator" title="Direct link to 2.1 生成器模型 SRResNetGenerator">​</a></h3>
<p>该网络基本结构模仿 SRResNet，内含：
· Initial Layer：9x9 大卷积核 + PReLU
· 8 个残差块（每块带有两层卷积 + BN + PReLU）
· 残差连接（ResNet 风格）
上采样层：
· 使用 PixelShuffle 实现图像上采样（从 16x16 → 64x64）
· 最终卷积 + Tanh：输出范围规范为 [-1, 1]</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">class SRResNetGenerator(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=2, out_channels=2, features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.initial = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(in_channels, features, kernel_size=9, padding=4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 8 Residual Blocks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        res_blocks = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for _ in range(8):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res_blocks.append(nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.BatchNorm2d(features)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.res_blocks = nn.Sequential(*res_blocks)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.mid_conv = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.upsample = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.final = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, out_channels, kernel_size=9, padding=4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Tanh()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x1 = self.initial(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        res = x1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for block in self.res_blocks:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res = res + block(res)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.mid_conv(res)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = out + x1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.upsample(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.final(out)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-定义判别器-discriminator">2.2 定义判别器 Discriminator<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#22-%E5%AE%9A%E4%B9%89%E5%88%A4%E5%88%AB%E5%99%A8-discriminator" class="hash-link" aria-label="Direct link to 2.2 定义判别器 Discriminator" title="Direct link to 2.2 定义判别器 Discriminator">​</a></h3>
<p>该判别器用于判断输入图像是否为真实高分图像，具体如下：
· 多层卷积+BN+LeakyReLU，最后输出为一个值
· 类似 PatchGAN 风格（结果为二维特征图）
· 最后一层采用 Sigmoid 激活，输出概率</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class Discriminator(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=4, features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.model = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(in_channels, features, 4, 2, 1),  # (B, 64, 32, 32)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 2, 4, 2, 1),  # (B, 128, 16, 16)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features * 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features * 2, features * 4, 4, 2, 1),  # (B, 256, 8, 8)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features * 4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features * 4, 1, 4, 1, 1),  # (B, 1, 7, 7) =&gt; PatchGAN 输出</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Sigmoid()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, lr_up, hr_or_fake):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 确保为[B, 2, 64, 64]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if lr_up.shape[-2:] != hr_or_fake.shape[-2:]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            raise ValueError(f"Shape mismatch: lr_up={lr_up.shape}, hr={hr_or_fake.shape}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = torch.cat([lr_up, hr_or_fake], dim=1)  # [B, 4, H, W]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.model(x)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-esrgan">3. ESRGAN<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#3-esrgan" class="hash-link" aria-label="Direct link to 3. ESRGAN" title="Direct link to 3. ESRGAN">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-生成器模型rdbnet">3.1 生成器模型RDBNet<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#31-%E7%94%9F%E6%88%90%E5%99%A8%E6%A8%A1%E5%9E%8Brdbnet" class="hash-link" aria-label="Direct link to 3.1 生成器模型RDBNet" title="Direct link to 3.1 生成器模型RDBNet">​</a></h3>
<p>使用多个 残差密集块（RRDB），用于深层次特征提取与稳定训练；每个 RRDB 由三个去 BN 的 DenseBlock 组成，通过局部和全局残差连接增强梯度传播、抑制信息丢失。整体流程为：输入图像经卷积提取初步特征 → 多层 RRDB 提取深层表示 → 上采样模块逐步恢复空间分辨率 → 最终输出</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Dense Block（去掉BN + 残差缩放）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class DenseBlock(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, channels=64, growth_channels=32):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.layers = nn.ModuleList()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for i in range(5):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.layers.append(nn.Conv2d(channels + i * growth_channels, growth_channels, 3, 1, 1))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.lrelu = nn.LeakyReLU(0.2, inplace=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.conv_last = nn.Conv2d(channels + 5 * growth_channels, channels, 3, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        inputs = [x]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for conv in self.layers:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            out = self.lrelu(conv(torch.cat(inputs, dim=1)))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            inputs.append(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.conv_last(torch.cat(inputs, dim=1))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return x + out * 0.2  # Local residual</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># RRDB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class RRDB(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, channels, growth_channels=32):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.block1 = DenseBlock(channels, growth_channels)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.block2 = DenseBlock(channels, growth_channels)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.block3 = DenseBlock(channels, growth_channels)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.block1(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.block2(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.block3(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return x + out * 0.2  # Global residual</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ESRGAN Generator (RRDBNet)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class RRDBNet(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=2, out_channels=2, features=64, num_blocks=8):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.conv_first = nn.Conv2d(in_channels, features, 3, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # RRDB trunk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.rrdb_blocks = nn.Sequential(*[RRDB(features) for _ in range(num_blocks)])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.trunk_conv = nn.Conv2d(features, features, 3, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Upsampling blocks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.upsample = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2, inplace=True),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.LeakyReLU(0.2, inplace=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.conv_last = nn.Conv2d(features, out_channels, 3, 1, 1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fea = self.conv_first(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        trunk = self.trunk_conv(self.rrdb_blocks(fea))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fea = fea + trunk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.upsample(fea)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.conv_last(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return out</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-判别器模型esrdiscriminator">3.2 判别器模型ESRDiscriminator<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#32-%E5%88%A4%E5%88%AB%E5%99%A8%E6%A8%A1%E5%9E%8Besrdiscriminator" class="hash-link" aria-label="Direct link to 3.2 判别器模型ESRDiscriminator" title="Direct link to 3.2 判别器模型ESRDiscriminator">​</a></h3>
<p>ESRDiscriminator 是一个深层 PatchGAN 判别器，通过逐层卷积下采样提取图像局部特征，并对 LR 图像与 HR 图像的拼接输入进行真假判别</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">class ESRDiscriminator(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=4, base_features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        def block(in_f, out_f, stride):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(in_f, out_f, 3, stride, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.LeakyReLU(0.2, inplace=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        layers = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(in_channels, base_features, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features, base_features, 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features, base_features * 2, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features * 2, base_features * 2, 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features * 2, base_features * 4, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features * 4, base_features * 4, 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features * 4, base_features * 8, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            block(base_features * 8, base_features * 8, 2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(base_features * 8, 1, 3, 1, 1)  # PatchGAN 输出</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.model = nn.Sequential(*layers)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, lr_up, hr_or_fake):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if lr_up.shape[-2:] != hr_or_fake.shape[-2:]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            raise ValueError(f"Shape mismatch: lr_up={lr_up.shape}, hr={hr_or_fake.shape}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = torch.cat([lr_up, hr_or_fake], dim=1)  # 拼接输入 [B, 4, H, W]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.model(x)</span><br></span></code></pre></div></div>
<h1>SRGAN及其消融试验</h1>
<p>以SRGAN为baseline，本文对比了四种情况，即</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-损失函数改进版">1. 损失函数改进版<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#1-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%94%B9%E8%BF%9B%E7%89%88" class="hash-link" aria-label="Direct link to 1. 损失函数改进版" title="Direct link to 1. 损失函数改进版">​</a></h2>
<p>除了使用传统的 MSE 和对抗损失，还使用了VGG perceptual loss（基于 VGG 网络的中间层）；MS-SSIM（多尺度结构相似性指标）</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-通道注意力机制版">2. 通道注意力机制版<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#2-%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%89%88" class="hash-link" aria-label="Direct link to 2. 通道注意力机制版" title="Direct link to 2. 通道注意力机制版">​</a></h2>
<p>在生成器的残差块或特征融合模块中引入 Channel Attention 模块，同时引入 Squeeze-and-Excitation（SE）通道注意力模块，并在每个残差块之后插入 SEBlock(features)</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">class SEBlock(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, channel, reduction=16):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super(SEBlock, self).__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.avg_pool = nn.AdaptiveAvgPool2d(1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.fc1 = nn.Conv2d(channel, channel // reduction, 1, bias=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.relu = nn.ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.fc2 = nn.Conv2d(channel // reduction, channel, 1, bias=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.sigmoid = nn.Sigmoid()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Squeeze: Global Average Pooling</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y = self.avg_pool(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Excitation: Fully connected layers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y = self.fc1(y)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y = self.relu(y)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y = self.fc2(y)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        y = self.sigmoid(y)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return x * y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class SRResNetGenerator(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=2, out_channels=2, features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super(SRResNetGenerator, self).__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.initial = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(in_channels, features, kernel_size=9, padding=4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 8 Residual Blocks with SE Blocks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        res_blocks = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for _ in range(8):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res_blocks.append(nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                SEBlock(features)  # Add SE Block after each residual block</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.res_blocks = nn.Sequential(*res_blocks)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.mid_conv = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.upsample = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.final = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, out_channels, kernel_size=9, padding=4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Tanh()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x1 = self.initial(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        res = x1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for block in self.res_blocks:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res = res + block(res)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.mid_conv(res)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = out + x1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.upsample(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.final(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-多尺度特征融合版">3. 多尺度特征融合版<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#3-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%89%88" class="hash-link" aria-label="Direct link to 3. 多尺度特征融合版" title="Direct link to 3. 多尺度特征融合版">​</a></h2>
<p>网络结构中引入多尺度特征处理模块（如使用 3x3、5x5、7x7 不同卷积核或金字塔结构），并将不同尺度特征拼接或加权融合，最后添加至 SRResNetGenerator 内部结构中</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">class MultiScaleFeatureFusion(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels, features):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super(MultiScaleFeatureFusion, self).__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 使用膨胀卷积增加感受野</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.scale1 = nn.Conv2d(in_channels, features, kernel_size=3, padding=1, dilation=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.scale2 = nn.Conv2d(in_channels, features, kernel_size=5, padding=2, dilation=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.scale3 = nn.Conv2d(in_channels, features, kernel_size=7, padding=3, dilation=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.fusion = nn.Conv2d(features * 3, features, kernel_size=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x1 = self.scale1(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x2 = self.scale2(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x3 = self.scale3(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        fused = torch.cat([x1, x2, x3], dim=1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.fusion(fused)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class SRResNetGenerator(nn.Module):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, in_channels=2, out_channels=2, features=64):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super(SRResNetGenerator, self).__init__()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.initial = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(in_channels, features, kernel_size=9, padding=4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Multi-scale feature fusion module</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.multi_scale_fusion = MultiScaleFeatureFusion(in_channels=features, features=features)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # 修改残差块，使用膨胀卷积</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        res_blocks = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for _ in range(8):  # 保持16个残差块</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res_blocks.append(nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(features, features, kernel_size=3, padding=2, dilation=2),  # 使用膨胀卷积</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.BatchNorm2d(features),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.Conv2d(features, features, kernel_size=3, padding=2, dilation=2),  # 使用膨胀卷积</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn.BatchNorm2d(features)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.res_blocks = nn.Sequential(*res_blocks)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.mid_conv = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features, kernel_size=3, padding=1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.BatchNorm2d(features)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.upsample = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, features * 4, 3, 1, 1),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PixelShuffle(2),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.PReLU(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.final = nn.Sequential(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Conv2d(features, out_channels, kernel_size=9, padding=4),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn.Tanh()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x1 = self.initial(x)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Multi-scale feature fusion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x2 = self.multi_scale_fusion(x1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        res = x1 + x2  # Combine initial and multi-scale fused features</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for block in self.res_blocks:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res = res + block(res)  # Residual learning</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.mid_conv(res)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = out + x1  # Add skip connection from initial input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        out = self.upsample(out)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return self.final(out)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-融合">4. 融合<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#4-%E8%9E%8D%E5%90%88" class="hash-link" aria-label="Direct link to 4. 融合" title="Direct link to 4. 融合">​</a></h2>
<p>同时采用：
· 感知 + MS-SSIM + MSE + GAN 损失；
· 多尺度结构；
· 通道注意力；</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-总结">5. 总结<a href="https://your-docusaurus-test-site.com/blog/12-%E7%9B%B8%E5%85%B3GAN%E5%8F%8A%E5%85%B6SRGAN%E6%B6%88%E8%9E%8D%E8%AF%95%E9%AA%8C#5-%E6%80%BB%E7%BB%93" class="hash-link" aria-label="Direct link to 5. 总结" title="Direct link to 5. 总结">​</a></h2>
<table><thead><tr><th>实验名称</th><th>改进点类型</th><th>主要操作</th><th>作用</th></tr></thead><tbody><tr><td><strong>1. 损失函数改进</strong></td><td>损失函数层面</td><td>引入 <strong>多种损失组合</strong>，如感知损失（VGG）、MS-SSIM 等</td><td>更符合人类视觉感知，提升图像质量</td></tr><tr><td><strong>2. 通道注意力机制</strong></td><td>网络结构层面</td><td>在生成器中加入 <strong>通道注意力模块（如 SE/CA）</strong></td><td>自适应关注重要特征通道，提升表示能力</td></tr><tr><td><strong>3. 多尺度特征融合</strong></td><td>网络结构层面</td><td>引入多个尺度（不同尺寸卷积核或下采样路径）进行特征融合</td><td>更好保留图像纹理和细节</td></tr><tr><td><strong>4. 融合模型</strong></td><td>综合增强</td><td>同时引入注意力 + 多尺度 + 改进损失</td><td>协同提升性能，验证组合优势</td></tr></tbody></table>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automated and Context-Aware Repair of Color-Related Accessibility Issues for Android Apps]]></title>
        <id>https://your-docusaurus-test-site.com/blog/05-Automated and Context-Aware Repair of Color-Related Accessibility Issues for Android Apps</id>
        <link href="https://your-docusaurus-test-site.com/blog/05-Automated and Context-Aware Repair of Color-Related Accessibility Issues for Android Apps"/>
        <updated>2025-06-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[1. 摘要]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-摘要">1. 摘要<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#1-%E6%91%98%E8%A6%81" class="hash-link" aria-label="Direct link to 1. 摘要" title="Direct link to 1. 摘要">​</a></h2>
<p>约 15% 的全球人口受到各种残障或视力障碍的影响，但许多移动端的用户体验（UX）设计师和开发者在开发 App 时并未重视可访问性问题。这意味着每七个人中就有一个用户在使用 App 时面临不平等的体验，这不仅影响用户，也可能违反相关法规。实际上，如果 App 开发时考虑可访问性，不仅能提升整体用户体验，还能提升商业价值。因此，已有不少研究和检测工具被提出用于识别可访问性问题。</p>
<p>然而，与检测相比，<strong>修复工作明显滞后</strong>，尤其是“颜色相关的可访问性问题”——比如文字对比度不足和图片对比度不佳，这类问题极大地影响了低视力用户和老年用户的使用体验，而当前的修复方法对此无能为力。</p>
<p>为此，我们提出了 Iris：一种自动化且具备上下文感知能力的方法，用于修复颜色相关的可访问性问题。该方法通过设计一致性的颜色替换策略和属性定位算法，在<strong>修复问题的同时保持 UI 风格的一致性</strong>。实验显示，Iris 可达到 91.38% 的修复成功率，且效率较高。用户调研也表明其结果令人满意，开发者反馈积极。我们在 GitHub 上提交的 40 个 Pull Request 中已有 9 个被合并，另有 4 个正在积极沟通后续修复。Iris 工具现已开源，旨在推动移动可访问性修复领域的进一步研究。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-introduction">2. introduction<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#2-introduction" class="hash-link" aria-label="Direct link to 2. introduction" title="Direct link to 2. introduction">​</a></h2>
<p>懒的讲了，感觉没啥用。反正大意就是解决这三个问题</p>
<p><strong>1.</strong> 修复后必须保持原始 UI 页面的设计风格一致性；
<strong>2.</strong> 必须准确定位待修复的 UI 组件及其颜色属性；
<strong>3.</strong> 修复结果需被真实用户和开发者接受，具备实用性。</p>
<p>作者提出了 iris，可以弄一个流程图体现该作者的研究工作</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">                  [1] APK 文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ┌───────────────────────────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        │        Xbot 检测工具           │ ← 基于 Accessibility Scanner</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        └───────────────────────────────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               输出内容包括：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               - 无障碍检测报告（JSON / XML）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               - UI 页面截图（PNG）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ┌────────────────────────────────────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        │               Iris 修复系统              │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        └────────────────────────────────────────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  1. 颜色参考数据库（Reference DB）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 收集 9978 个 App 的 UI 配色</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 用于推荐合适的替换颜色</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  2. 上下文感知颜色选择（Context-aware）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 保持风格一致性（HSV 模型、色轮协调）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 决定修改 foreground 还是 background</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  3. 属性定位模块（Attribute-to-Repair）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 定位 XML 或 Java 中待修复组件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 分析 textColor、background 等属性</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  4. 图像修复模块（仅针对图标）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 判断功能性 vs 装饰性图像</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     - 调整颜色或替换 vector 图标</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ┌───────────────────────────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        │         修复后的 APK 输出       │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        └───────────────────────────────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-preliminary">3. Preliminary<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#3-preliminary" class="hash-link" aria-label="Direct link to 3. Preliminary" title="Direct link to 3. Preliminary">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-标准">3.1 标准<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#31-%E6%A0%87%E5%87%86" class="hash-link" aria-label="Direct link to 3.1 标准" title="Direct link to 3.1 标准">​</a></h3>
<p>需要解决以下问题：</p>
<ol>
<li>普通文本要求前景色与背景色的对比度 ≥4.5:1*</li>
<li>大号加粗文本则要求 ≥3:1</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="32-颜色实现方式">3.2 颜色实现方式<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#32-%E9%A2%9C%E8%89%B2%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F" class="hash-link" aria-label="Direct link to 3.2 颜色实现方式" title="Direct link to 3.2 颜色实现方式">​</a></h2>
<p>在 xml 文件中，颜色一般是这样表达的</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TextView android:textColor="#80ff0000" /&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;Button android:background="#80ff0000" /&gt;</span><br></span></code></pre></div></div>
<p>提出 iris 用于修复这样的问题</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="33-检测工具提供的输入">3.3 检测工具提供的输入<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#33-%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E6%8F%90%E4%BE%9B%E7%9A%84%E8%BE%93%E5%85%A5" class="hash-link" aria-label="Direct link to 3.3 检测工具提供的输入" title="Direct link to 3.3 检测工具提供的输入">​</a></h2>
<p>这部分有很多，但是这个作者毫无创新，只是单纯的将各种工具整合而已（也有可能我不是这个方向的，不知道主流是什么样的^_^）</p>
<h1>4. Approach</h1>
<p>这块是 iris 的核心部分，主要流程如下</p>
<ol>
<li><strong>参考数据库构建（Reference DB Construction）</strong></li>
<li><strong>上下文感知的颜色选择（Context-aware Color Selection）</strong></li>
<li><strong>待修复属性定位（Attribute-to-Repair Localization）</strong></li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-reference-db-construction">4.1 Reference DB Construction<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#41-reference-db-construction" class="hash-link" aria-label="Direct link to 4.1 Reference DB Construction" title="Direct link to 4.1 Reference DB Construction">​</a></h2>
<p><strong>目的</strong>：提供颜色替换时的“设计参考”。</p>
<p><strong>流程</strong>：</p>
<ul>
<li>使用 Xbot 对近 9978 个 APK 检测；</li>
<li>收集其中未出现颜色对比度问题的 UI 组件；</li>
<li>根据组件类型分类（如 Button、TextView 等）；</li>
<li>从 UI 截图中提取每个组件的前景色和背景色；</li>
<li>使用** **<code>getcolors()</code> 获取最常出现的两种颜色；</li>
<li>对比颜色值，保留满足对比度要求的颜色对，构建数据库。</li>
</ul>
<p><strong>优势</strong>：使用真实 App 中“被认可的配色”作为修复备选，<strong>提高了颜色风格的一致性</strong>。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-context-aware-color-selection">4.2 Context-Aware Color Selection<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#42-context-aware-color-selection" class="hash-link" aria-label="Direct link to 4.2 Context-Aware Color Selection" title="Direct link to 4.2 Context-Aware Color Selection">​</a></h2>
<p>算法流程在原文中给了，简单来说就是</p>
<ul>
<li>输入：当前问题颜色、颜色候选集、页面色调类型、偏转角；</li>
<li>筛选候选颜色集，计算最小“色调距离”；</li>
<li>如果没有合适候选色，就使用 HSV 微调获得备选颜色；</li>
<li>返回最接近原设计的最优替换色。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="43-attribute-to-repair-localization">4.3 Attribute-to-Repair Localization<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#43-attribute-to-repair-localization" class="hash-link" aria-label="Direct link to 4.3 Attribute-to-Repair Localization" title="Direct link to 4.3 Attribute-to-Repair Localization">​</a></h2>
<p>根据 Xbot 报告，精准找到需要修改的 XML 属性或代码</p>
<p>定位方式：</p>
<ul>
<li><strong>组件 ID（resource-id）存在时</strong>：可直接在反编译的 layout 中精确查找；</li>
<li><strong>仅有 bounds 坐标时</strong>：通过坐标在 layout tree 中找到组件，再通过文本等信息比对 XML 结构中的** **<code>android:text</code>属性，进行模糊定位。</li>
</ul>
<h1>5. 复现</h1>
<p>前文我们知道了该论文有两部分组成，Xbot 和 iris 部分，因此我们一点一点来，先讲 Xbot 部分</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="51-xbot">5.1 Xbot<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#51-xbot" class="hash-link" aria-label="Direct link to 5.1 Xbot" title="Direct link to 5.1 Xbot">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="511-下载原代码">5.1.1 下载原代码<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#511-%E4%B8%8B%E8%BD%BD%E5%8E%9F%E4%BB%A3%E7%A0%81" class="hash-link" aria-label="Direct link to 5.1.1 下载原代码" title="Direct link to 5.1.1 下载原代码">​</a></h3>
<p>首先把 GitHub 仓库给 down 下来</p>
<p>仓库地址：<a href="https://github.com/tjusenchen/Xbot" target="_blank" rel="noopener noreferrer">https://github.com/tjusenchen/Xbot</a></p>
<p>这是一个很老的代码，需要用到 py2 来运行，mac 上是不能通过 conda 下载 py2 版本的，因此这般选择 pyenv（也是一种管理工具，和 conda 差不多），如果是 windows 用户的话可忽略</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="512-安装模拟器">5.1.2 安装模拟器<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#512-%E5%AE%89%E8%A3%85%E6%A8%A1%E6%8B%9F%E5%99%A8" class="hash-link" aria-label="Direct link to 5.1.2 安装模拟器" title="Direct link to 5.1.2 安装模拟器">​</a></h3>
<p>模拟器也要和仓库中的 readme 中一样，选择 Android 7.1.1+PIX，如果太新的话会导致兼容性问题。</p>
<p>在创建好了模拟器之后，可以通过该命令检查是否连上了</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb devices</span><br></span></code></pre></div></div>
<p>跳出来你的模拟器名字就 ok 了，如果你没看到的话，有很大原因是你没启动（我因为这个问题卡了一下午，md）</p>
<p>当然，使用的前提是你得先把 adb 下了，可以通过如下命令查看</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb version</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Android Debug Bridge version 1.0.41</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Version ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>系统默认一般是会带有的，路径如下</p>
<p>macOS:<code>~/Library/Android/sdk/platform-tools/adb</code></p>
<p>Windows:C:\Users&lt;用户名&gt;\AppData\Local\Android\Sdk\platform-tools\adb`</p>
<p>如果发现没的话也问题不大，去官网下一个</p>
<p>官网地址：<a href="https://developer.android.com/studio/releases/platform-tools" target="_blank" rel="noopener noreferrer">https://developer.android.com/studio/releases/platform-tools</a></p>
<p>然后解压添加到环境变量一条龙就 ok 了</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="513-安装-apk-文件">5.1.3 安装 apk 文件<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#513-%E5%AE%89%E8%A3%85-apk-%E6%96%87%E4%BB%B6" class="hash-link" aria-label="Direct link to 5.1.3 安装 apk 文件" title="Direct link to 5.1.3 安装 apk 文件">​</a></h3>
<p>这部分就不用多说了，把 adb 命名下载好了之后就 adb install，例如</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb install path/to/your_app.apk</span><br></span></code></pre></div></div>
<p>需要安装两个，分别是 GAS 和 Vol 的这两个 apk，都是在仓库里给了的，直接安装就行。</p>
<p>**尤其需要注意！！！**GAS 下载了之后，需要现在模拟器里设置- accessibility-GAS，打开服务。打开之后会跳出一个蓝色框框，然后再代码中修改你的这个悬浮窗的坐标，不然会造成闪退的情况！！！！！！修改的代码叫做 explore_activaity.py，scan_and_return 函数中</p>
<p>还有一个 vol 就没啥好说的了，下了就行，这是一个景点经典用 apk</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="514-运行-xbot">5.1.4 运行 Xbot<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#514-%E8%BF%90%E8%A1%8C-xbot" class="hash-link" aria-label="Direct link to 5.1.4 运行 Xbot" title="Direct link to 5.1.4 运行 Xbot">​</a></h3>
<p><strong>1. 准备工作：</strong></p>
<ol>
<li>Python 环境</li>
</ol>
<ul>
<li>推荐使用** ****Python 2.7**</li>
<li>所需库基本为标准库：如** <strong><code>os</code>,</strong> <strong><code>commands</code>,</strong> <strong><code>csv</code>,</strong> <strong><code>shutil</code>,</strong> **<code>time</code></li>
</ul>
<ol start="2">
<li>Genymotion 模拟器准备</li>
</ol>
<ul>
<li>已安装** ****Genymotion Desktop**</li>
<li>启动一个设备（例如** **<code>127.0.0.1:6555</code>）</li>
<li>模拟器 root 权限已开启（<code>adb root</code> 可运行）</li>
</ul>
<p><strong>2. 文件与路径结构检查</strong></p>
<p>目录结构（假设在** **<code>Xbot-main</code> 下运行）</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">├── code/                      # Python 脚本主目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── run_xbot.py            # 主运行脚本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── explore_activity.py    # 动态探索逻辑</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── repkg_apk.py           # 重打包逻辑（已用可选）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── apks/                      # 存放待测 APK 的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └── xxx.apk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── config/                    # 相关配置</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── coolapk.keystore</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ├── libs/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   └── android-platforms/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── results/                   # 自动创建，输出目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── storydroid/               # 自动创建，用于参数记录等</span><br></span></code></pre></div></div>
<p><strong>3. APK 文件命名注意：</strong></p>
<ul>
<li><code>.apk</code> 文件放在** **<code>apks/</code> 中，**不要加中文名或特殊字符**</li>
<li>如** **<code>a2dp.Vol_133.apk</code></li>
</ul>
<p><strong>4. 代码准备工作</strong></p>
<ol>
<li>确认** **<code>run_xbot.py</code> 开头几项路径为你本机配置，例如</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">java_home_path = '/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home/'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sdk_platform_path = '/Users/yourname/.../android-platforms/'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lib_home_path = '/Users/yourname/.../libs/'</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<ol start="2">
<li>清理旧 outputs（可选）</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">rm -rf results/ storydroid/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p><strong>5. 执行命令</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd Xbot-main/code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python run_xbot.py 127.0.0.1:6555 ../main-folder/apks/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># adb</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adb devices.   # 查看设备名字</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p><strong>6. 运行 xml 修复</strong></p>
<p>Xbot 只有原始 apk 页面的 Xbot，还需要通过 issues 来生成新的 xml 以让 iris 知道哪个组件有问题</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python3 Xbot-main/code/txt2irisxml.py \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Xbot-main/results/outputs/a2dp.Vol_133/issues/a2dp.Vol.EditDevice/a2dp.Vol.EditDevice.txt \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Xbot-main/results/outputs/a2dp.Vol_133/issues/a2dp.Vol.EditDevice/AccessibilityScanner.xml</span><br></span></code></pre></div></div>
<p>贴出 txt2irisxml 代码，放在 code 目录下面</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># -*- coding: utf-8 -*-</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import xml.etree.ElementTree as ET</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def parse_txt(txt_path):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    with open(txt_path, 'r', encoding='utf-8') as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        lines = [line.strip() for line in f.readlines() if line.strip()]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    issues = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    i = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while i &lt; len(lines):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        line = lines[i]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # --- Item label / Missing label</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if "Item label" in line:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res_id = lines[i] if i &lt; len(lines) else "unknown"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            issues.append({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "Type": "MissingLabel",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "ResourceID": res_id,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "Class": "android.widget.EditText"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # --- Text contrast</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        elif "Text contrast" in line:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res_id = lines[i] if i &lt; len(lines) else "unknown"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ratio = "N/A"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if i &lt; len(lines) and "contrast ratio is" in lines[i]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    ratio = lines[i].split("contrast ratio is")[1].split(".")[0] + "." + lines[i].split("contrast ratio is")[1].split(".")[1][:2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                except:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    pass</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            issues.append({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "Type": "LowTextContrast",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "ResourceID": res_id,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "Class": "android.widget.TextView",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "ContrastRatio": ratio</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # --- Touch target too small</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        elif "Touch target" in line:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            res_id = lines[i] if i &lt; len(lines) else "unknown"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            issues.append({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "Type": "TouchTargetTooSmall",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "ResourceID": res_id,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "Class": "android.widget.Button"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            i += 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return issues</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def write_xml(issues, output_path):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    root = ET.Element("AccessibilityIssues")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for issue in issues:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        item = ET.SubElement(root, "Issue")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ET.SubElement(item, "Type").text = issue.get("Type", "Unknown")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ET.SubElement(item, "ResourceID").text = issue.get("ResourceID", "unknown")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ET.SubElement(item, "Class").text = issue.get("Class", "android.view.View")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if "ContrastRatio" in issue:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ET.SubElement(item, "ContrastRatio").text = issue["ContrastRatio"]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tree = ET.ElementTree(root)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    os.makedirs(os.path.dirname(output_path), exist_ok=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tree.write(output_path, encoding="utf-8", xml_declaration=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f"✅ Created XML: {output_path}")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == "__main__":</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if len(sys.argv) != 3:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print("Usage: python txt2irisxml.py input.txt output.xml")</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        sys.exit(1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    txt_file = sys.argv[1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    xml_file = sys.argv[2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    issues = parse_txt(txt_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    write_xml(issues, xml_file)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p><strong>7. 运行结果</strong></p>
<p>在/results/apk_name 中。主要需要的是 outputs 这个文件夹</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="52-iris">5.2 IRIS<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#52-iris" class="hash-link" aria-label="Direct link to 5.2 IRIS" title="Direct link to 5.2 IRIS">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="521-解压-zip-文件">5.2.1. 解压 zip 文件<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#521-%E8%A7%A3%E5%8E%8B-zip-%E6%96%87%E4%BB%B6" class="hash-link" aria-label="Direct link to 5.2.1. 解压 zip 文件" title="Direct link to 5.2.1. 解压 zip 文件">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd /root</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">unzip iris-mobile-master.zip</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mv iris-mobile-master iris-mobiles</span><br></span></code></pre></div></div>
<p>同时需要将之前 Xbot 的输出 outputs 存放在根目录下，zip 是原始在 GitHub 中下载的</p>
<p>GitHub 地址：<a href="https://github.com/tjuyuxinzhang/iris-mobile" target="_blank" rel="noopener noreferrer">https://github.com/tjuyuxinzhang/iris-mobile</a></p>
<ol start="2">
<li>复制 Xbot 输出和 APK 到 IRIS 指定位置</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p /root/iris-mobile/code/data/xbot_output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cp -r /root/outputs/a2dp.Vol_133 /root/iris-mobile/code/data/xbot_output/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p /root/iris-mobile/apks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cp /root/outputs/a2dp.Vol_133.apk /root/iris-mobile/apks/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="522-修改一些路径代码">5.2.2 修改一些路径代码<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#522-%E4%BF%AE%E6%94%B9%E4%B8%80%E4%BA%9B%E8%B7%AF%E5%BE%84%E4%BB%A3%E7%A0%81" class="hash-link" aria-label="Direct link to 5.2.2 修改一些路径代码" title="Direct link to 5.2.2 修改一些路径代码">​</a></h3>
<ol>
<li>repair_repack_class.py</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">results_folder = "/root/iris-mobile"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">resultPath = '/root/iris-mobile/refDB'  # 若没有这个文件夹可先建空目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputsPath = '/root/outputs'</span><br></span></code></pre></div></div>
<ol start="2">
<li>harmonizationTs2.py</li>
</ol>
<p>把 250 行的 plt 部分注释了（如果用的是虚拟机，无图形页面的话）</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="523-切换目录并运行-iris-修复脚本">5.2.3 切换目录并运行 IRIS 修复脚本<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#523-%E5%88%87%E6%8D%A2%E7%9B%AE%E5%BD%95%E5%B9%B6%E8%BF%90%E8%A1%8C-iris-%E4%BF%AE%E5%A4%8D%E8%84%9A%E6%9C%AC" class="hash-link" aria-label="Direct link to 5.2.3 切换目录并运行 IRIS 修复脚本" title="Direct link to 5.2.3 切换目录并运行 IRIS 修复脚本">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd /root/iris-mobile/code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python2 repair_repack_class.py --app_name a2dp.Vol_133</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="524-运行结果">5.2.4 运行结果<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#524-%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C" class="hash-link" aria-label="Direct link to 5.2.4 运行结果" title="Direct link to 5.2.4 运行结果">​</a></h3>
<p>需要包含这些东西</p>
<ol>
<li>decompiling</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">decompiling...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Using Apktool 2.4.1 on a2dp.Vol_133.apk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Loading resource table...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Decoding AndroidManifest.xml with resources...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Loading resource table from file: /root/.local/share/apktool/framework/1.apk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Regular manifest package...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Decoding file-resources...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Decoding values */* XMLs...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Baksmaling classes.dex...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Copying assets and libs...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Copying unknown files...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">I: Copying original files...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">act_T_Alpha</span><br></span></code></pre></div></div>
<ol start="2">
<li>color layout</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">id_bound_colorSet</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{'Path': (['#817278', '#F9EEF0'], 4.5, 'ManageData', '', 'Text contrast'), 'Action:': (['#F7ECEE', '#F9EEF0'], 3, 'CustomIntentMaker', 'TextView', 'Text contrast'), 'title': (['#2979FF', '#F9EEF0'], 4.5, 'Preferences', '', 'Text contrast'), 'Data:': (['#FFFFFF', '#F9EEF0'], 3, 'CustomIntentMaker', 'TextView', 'Text contrast'), 'empty': (['#FFFFFF', '#F9EEF0'], 3, 'ProviderList', '', 'Text contrast'), 'Type:': (['#FFFFFF', '#F9EEF0'], 3, 'CustomIntentMaker', 'TextView', 'Text contrast'), 'Output': (['#817278', '#F9EEF0'], 4.5, 'ManageData', '', 'Text contrast'), 'pi_tv_name': (['#FFFFFF', '#F9EEF0'], 3, 'PackagesChooser', '', 'Text contrast')}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">waitChangeColor_self</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{'pi_tv_name': ('#585858', ['#FFFFFF', '#F9EEF0'], 3), 'title': ('#2153AE', ['#2979FF', '#F9EEF0'], 4.5), 'Data:': ('#585858', ['#FFFFFF', '#F9EEF0'], 3), 'Output': ('#504348', ['#817278', '#F9EEF0'], 4.5), 'Action:': ('', ['#F7ECEE', '#F9EEF0'], 3), 'Type:': ('#585858', ['#FFFFFF', '#F9EEF0'], 3), 'Path': ('#504348', ['#817278', '#F9EEF0'], 4.5), 'empty': ('#585858', ['#FFFFFF', '#F9EEF0'], 3)}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">colorToChange_self</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{'Path': '#504348', 'title': '#2153AE', 'Data:': '#585858', 'empty': '#585858', 'Type:': '#585858', 'Output': '#504348', 'pi_tv_name': '#585858'}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">['#F7ECEE', '#F9EEF0']</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">colorToChange_Layout</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{'Path': '#504348', 'title': '#2153AE', 'Action:': '#000000', 'Data:': '#585858', 'empty': '#585858', 'Type:': '#585858', 'Output': '#504348', 'pi_tv_name': '#585858'}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">imageId_Name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{('Data:', 'TextView'): '[0,332][263,436]', ('Path', 'TextView'): '[0,524][532,575]', ('Type:', 'TextView'): '[0,453][263,557]', ('pi_tv_name', 'TextView'): '[173,1610][954,1741]', ('Action:', 'TextView'): '[0,211][263,315]', ('title', 'TextView'): '[42,1756][626,1794]', ('empty', 'TextView'): '[53,263][1027,601]', ('Output', 'TextView'): '[465,575][614,669]'}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{'Path': '#504348', '[0,453][263,557]': '#585858', 'title': '#2153AE', '[0,332][263,436]': '#585858', 'empty': '#585858', '[0,211][263,315]': '#000000', 'Output': '#504348', 'pi_tv_name': '#585858'}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">waitChangeColor_self</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{'pi_tv_name': ('#585858', ['#FFFFFF', '#F9EEF0'], 3), 'title': ('#2153AE', ['#2979FF', '#F9EEF0'], 4.5), 'Data:': ('#585858', ['#FFFFFF', '#F9EEF0'], 3), 'Output': ('#504348', ['#817278', '#F9EEF0'], 4.5), 'Action:': ('', ['#F7ECEE', '#F9EEF0'], 3), 'Type:': ('#585858', ['#FFFFFF', '#F9EEF0'], 3), 'Path': ('#504348', ['#817278', '#F9EEF0'], 4.5), 'empty': ('#585858', ['#FFFFFF', '#F9EEF0'], 3)}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">recompile...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">('time cost', 327.10186195373535, 's')</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="525-修复后的-apk-文件">5.2.5 修复后的 apk 文件<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#525-%E4%BF%AE%E5%A4%8D%E5%90%8E%E7%9A%84-apk-%E6%96%87%E4%BB%B6" class="hash-link" aria-label="Direct link to 5.2.5 修复后的 apk 文件" title="Direct link to 5.2.5 修复后的 apk 文件">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">/root/iris-mobile/repackaged/a2dp.Vol_133.apk</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="526-将其放在-mac-上的-apk-文件夹中签名下载运行xbot-再次比对">5.2.6 将其放在 mac 上的 apk 文件夹中，签名下载运行（Xbot 再次比对）<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#526-%E5%B0%86%E5%85%B6%E6%94%BE%E5%9C%A8-mac-%E4%B8%8A%E7%9A%84-apk-%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E7%AD%BE%E5%90%8D%E4%B8%8B%E8%BD%BD%E8%BF%90%E8%A1%8Cxbot-%E5%86%8D%E6%AC%A1%E6%AF%94%E5%AF%B9" class="hash-link" aria-label="Direct link to 5.2.6 将其放在 mac 上的 apk 文件夹中，签名下载运行（Xbot 再次比对）" title="Direct link to 5.2.6 将其放在 mac 上的 apk 文件夹中，签名下载运行（Xbot 再次比对）">​</a></h3>
<ol>
<li>签名 apk</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">/Users/qijiazhou/Library/Android/sdk/build-tools/36.0.0/apksigner sign \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --ks ~/Desktop/test-key.jks \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --ks-key-alias testkey \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --ks-pass pass:123456 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --key-pass pass:123456 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --out ~/Desktop/apk/a2dp.Vol_133_signed.apk \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ~/Desktop/apk/a2dp.Vol_133.apk</span><br></span></code></pre></div></div>
<ol start="2">
<li>安装测试</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">adb install -r ~/Desktop/apk/a2dp.Vol_133_signed.apk</span><br></span></code></pre></div></div>
<p>接着就是再运行 Xbot 的过程，将其放入 main- folder/apks 文件夹中</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-experiments">6. Experiments<a href="https://your-docusaurus-test-site.com/blog/05-Automated%20and%20Context-Aware%20Repair%20of%20Color-Related%20Accessibility%20Issues%20for%20Android%20Apps#6-experiments" class="hash-link" aria-label="Direct link to 6. Experiments" title="Direct link to 6. Experiments">​</a></h2>
<p>用户调查就不说了，按照复现流程走下来应该是能一样的。当然，此处可以讲一下修复成功率计算公式评价指标</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Repire = 修复成功的问题数/该app原始问题数 * 100%</span><br></span></code></pre></div></div>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[欢迎来到FEMATHS小组学习日志]]></title>
        <id>https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts</id>
        <link href="https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[FEMATHS 学习小组的故事可以追溯到 2023 年 6 月。当时，JoyBun、zqqqqqqj1110 和 Tanger 三人决定一起攻读与 PINN（Physics-Informed Neural Networks）相关的论文，以突破各自在学习中遇到的瓶颈。]]></summary>
        <content type="html"><![CDATA[<p>FEMATHS 学习小组的故事可以追溯到 <strong>2023 年 6 月</strong>。当时，<a href="https://github.com/JoyBun" target="_blank" rel="noopener noreferrer">JoyBun</a>、<a href="https://github.com/zqqqqqqj1110" target="_blank" rel="noopener noreferrer">zqqqqqqj1110</a> 和 <a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer">Tanger</a> 三人决定一起攻读与 <strong>PINN</strong>（<em>Physics-Informed Neural Networks</em>）相关的论文，以突破各自在学习中遇到的瓶颈。</p>
<p>但在阅读过程中，大家逐渐意识到：不仅 <a href="https://github.com/JoyBun" target="_blank" rel="noopener noreferrer">JoyBun</a> 和 <a href="https://github.com/zqqqqqqj1110" target="_blank" rel="noopener noreferrer">zqqqqqqj1110</a> 对 PINN 感到困惑，连相对熟悉一些的 <a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer">Tanger</a> 也有许多难以理解的地方。于是我们决定边读论文边做笔记。虽然这些笔记可能显得 <strong>粗浅、幼稚</strong>，甚至不乏理解上的偏差，但我们仍希望将它们整理出来。我们相信，通过写笔记的方式，可以尽可能清晰地梳理出 <strong>PINN</strong> 以及人工智能相关论文中的核心思想和原理。我们希望用最朴素的学习方法，把复杂的内容讲明白——<strong>用简单的努力，积累不平凡的价值</strong>。</p>
<p>这，就是 <strong>FEMATHS 小组学习日志</strong> 的由来。</p>
<p>后来，随着 Tanger 面临考研与工作的压力，科研学习和小组学习日志一度中断。直到 <strong>2025 年</strong>，桂林电子科技大学数学与计算科学学院公布拟录取名单，Tanger 顺利被录取。这也成为重新启动学习日志的契机——新的笔记就此续写。</p>
<p>这期间我们也结识了一些新的朋友，小组的视野逐渐拓展，开始探索更多方向。我们讨论决定，将围绕<strong>计算数学</strong>与部分<strong>机器学习</strong>领域，构建一个开放共享的 Wiki，并系统阅读相关领域的重要论文。我们利用 ai 技术创造出了新的网站 logo 以及公众号“山海数模”，如下：</p>
<p align="center"><img src="https://s2.loli.net/2025/06/12/BzStJo2weFED4vQ.jpg" alt="logo"></p>
<p align="center"><img src="https://s2.loli.net/2025/06/12/9aDkEfKWvUMrjnm.jpg" alt="logo"></p>
<p>在正式开始撰写这些内容之前，我们一致认为，应当从最基础、也是最关键的问题讲起——<strong>从入门到入土？不，是精通！科技论文完全指南</strong>。<br>
<!-- -->因此，我们决定将这个主题作为本知识普及网站的第一个系列内容。</p>
<p>本系列将分为以下四个部分展开：</p>
<ul>
<li>🍀 <strong>到底什么是科技论文</strong></li>
<li>🌴 <strong>如何找到一篇合适的科技论文</strong></li>
<li>🌵 <strong>如何正确且高效地阅读一篇科技论文</strong></li>
<li>🌾 <strong>如何写出一篇优秀的科技论文</strong></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="什么是科技论文">什么是科技论文？<a href="https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A7%91%E6%8A%80%E8%AE%BA%E6%96%87" class="hash-link" aria-label="Direct link to 什么是科技论文？" title="Direct link to 什么是科技论文？">​</a></h2>
<p>我们通常对科技论文的认知是一串富有逻辑的话语，它能够清晰地描述知识和技术，展示作者是如何从问题出发，通过一系列合理的推理、实验或模型构建，最终获得有价值的结论。</p>
<p>一篇优秀的科技论文不仅仅是“写出来”的成果，更是作者对问题深入思考和探索的结晶。它需要做到内容准确、结构清晰、论证严谨，并具备可重复性和可验证性。论文的语言虽理性克制，却承担着极大的知识传递功能，是推动学术交流和科技进步的核心载体。</p>
<p>因此，科技论文不仅是表达“我做了什么”，更是要清楚地传达“为什么做、怎么做、结果是什么、又说明了什么”。它是科研工作者与世界对话的桥梁，也是知识体系持续演化的基础环节。</p>
<p>接下来我们讨论科技论文的类型</p>
<p>如果你已经阅读过一些科研论文，或者对这方面有一定了解，相信下面这些术语你一定不会感到陌生：</p>
<ul>
<li><em>Research Article</em></li>
<li><em>Review Article</em></li>
<li><em>Short Communication</em></li>
<li><em>Technical Report</em></li>
<li><em>Case Study</em></li>
<li><em>Conference Paper</em></li>
<li><em>Perspective / Opinion / Commentary</em></li>
<li><em>Letter / Correspondence</em></li>
<li><em>Method / Protocol Paper</em></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="常见的科技论文类型">常见的科技论文类型<a href="https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts#%E5%B8%B8%E8%A7%81%E7%9A%84%E7%A7%91%E6%8A%80%E8%AE%BA%E6%96%87%E7%B1%BB%E5%9E%8B" class="hash-link" aria-label="Direct link to 常见的科技论文类型" title="Direct link to 常见的科技论文类型">​</a></h2>
<p>这些不同类型的科技论文各有其功能与侧重点，在学术交流中承担着不同角色。接下来，我们将逐一介绍它们的定义与作用，帮助你建立起对科技论文体系的基本认识。</p>
<table><thead><tr><th>类型</th><th>定义</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>Research Article</strong><br>研究论文</td><td>报告一项原创性的研究成果，遵循 IMRaD 结构（引言-方法-结果-讨论）</td><td>内容完整、结构严谨、可复现性强，是期刊论文主力</td><td>科研项目主成果发表、毕业论文、科研申报</td></tr><tr><td><strong>Review Article</strong><br>综述论文</td><td>总结、分析某一领域的研究进展与趋势</td><td>引用多、层次清晰、不包含新实验数据</td><td>研究生开题准备、初入领域者查阅</td></tr><tr><td><strong>Short Communication</strong><br>简报论文</td><td>报告一项尚未完成的研究初步成果</td><td>篇幅短、信息密度高、发表快</td><td>新发现速报、阶段性成果通报</td></tr><tr><td><strong>Technical Report</strong><br>技术报告</td><td>详细描述某项技术或工程实现过程</td><td>强调实践性、非正式发表</td><td>工程开发、软件/算法实现说明</td></tr><tr><td><strong>Case Study</strong><br>案例研究</td><td>通过个案探讨具有代表性的问题</td><td>情境真实、分析具体、有启发性</td><td>医学、管理、社会科学研究</td></tr><tr><td><strong>Conference Paper</strong><br>会议论文</td><td>会议展示成果，可收录于会议论文集</td><td>审稿快、互动性强、有时可扩展为期刊</td><td>初步研究发表、寻求同行反馈</td></tr><tr><td><strong>Perspective / Opinion / Commentary</strong><br>视角/观点/评论文章</td><td>表达作者对某研究问题的独立见解</td><td>观点突出、富启发性、可有争议性</td><td>领域热点讨论、研究方向引导</td></tr><tr><td><strong>Letter / Correspondence</strong><br>来信/通讯</td><td>简短讨论、评论或快速报告小成果</td><td>篇幅短、响应快、适用于学术互动</td><td>对已有论文回应、简短成果共享</td></tr><tr><td><strong>Method / Protocol Paper</strong><br>方法/协议论文</td><td>描述实验、计算或研究方法的具体步骤</td><td>可复现性高、步骤详细</td><td>工具方法共享、技术标准化</td></tr></tbody></table>
<p>我们接下来将以最常见、也是科研人员最常阅读与撰写的论文形式——**Research Article（研究论文）**为例，来展开讲解一篇科技论文的标准结构。</p>
<p>研究论文通常遵循一个被广泛接受的结构化写作框架，即 <strong>IMRaD 模式</strong>：即<strong>I – Introduction（引言）</strong>、<strong>M – Methods（方法）</strong> 、<strong>R – Results（结果）</strong>、<strong>A - Abstract（摘要）<strong>和</strong>D – Discussion（讨论）</strong>。</p>
<table><thead><tr><th>结构部分</th><th>英文名称</th><th>内容简介</th><th>写作要点与目的</th></tr></thead><tbody><tr><td>摘要</td><td>Abstract</td><td>对研究的目的、方法、主要结果和结论进行简洁总结。通常 200–300 字。</td><td>独立成篇、简明扼要，帮助读者快速了解整篇文章的核心信息。</td></tr><tr><td>引言</td><td>Introduction</td><td>说明研究背景、已有工作、待解决的问题和研究目的。</td><td>明确“研究动机”，交代“为什么做”以及“本文的贡献”。</td></tr><tr><td>方法</td><td>Methods</td><td>描述实验设计、数据来源、模型方法、算法流程、技术路线等。</td><td>强调可复现性，写清楚“怎么做”，确保别人能照着你的方法重复研究。</td></tr><tr><td>结果</td><td>Results</td><td>呈现研究所得的关键数据、图表和实验结果。</td><td>客观陈述发现，“得到了什么”，不做解释，使用图表或数据增强表达效果。</td></tr><tr><td>讨论</td><td>Discussion</td><td>分析和解释结果的意义，讨论其对领域的贡献、限制和未来方向。</td><td>深入讨论结果“说明了什么”，体现批判性思维，与他人研究进行对比。</td></tr><tr><td>结论（可选）</td><td>Conclusion</td><td>简要总结全文研究内容及其意义，强调研究的价值或应用前景。</td><td>突出研究亮点，避免重复讨论，强化研究的整体贡献。</td></tr><tr><td>参考文献</td><td>References</td><td>列出文中引用的全部文献。</td><td>符合期刊引用格式，完整准确，体现研究的理论基础和关联。</td></tr></tbody></table>
<hr>
<p>这种结构的最大优势在于逻辑清晰、模块分明，有助于读者快速理解研究的核心内容，也方便科研人员之间的交流与复现。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="research-article-示例解析">Research Article 示例解析<a href="https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts#research-article-%E7%A4%BA%E4%BE%8B%E8%A7%A3%E6%9E%90" class="hash-link" aria-label="Direct link to Research Article 示例解析" title="Direct link to Research Article 示例解析">​</a></h2>
<p>为了更直观地理解一篇科技论文的结构，我们将以本人发表的一篇研究论文《A Multi-Layer Classifier Model XR-KS of Human Activity Recognition for the Problem of Similar Human Activity》为例，对其各部分内容进行拆解分析。希望借此帮助大家掌握一篇标准 Research Article 的行文方式与写作要点。</p>
<p align="center"><img src="https://s2.loli.net/2025/06/12/wTvohC8WHIEU9tJ.png" alt="logo"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="论文结构解析">论文结构解析<a href="https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts#%E8%AE%BA%E6%96%87%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90" class="hash-link" aria-label="Direct link to 论文结构解析" title="Direct link to 论文结构解析">​</a></h3>
<table><thead><tr><th>部分</th><th>内容摘要（基于本论文）</th><th>写作提示与说明</th></tr></thead><tbody><tr><td><strong>标题</strong></td><td>A Multi-Layer Classifier Model XR-KS of Human Activity Recognition for the Problem of Similar Human Activity</td><td>简明传达研究主题，聚焦“多层分类模型 + 相似人类行为识别”问题。</td></tr><tr><td><strong>摘要</strong></td><td>简要介绍研究背景、人类活动识别中的挑战、提出的 XR-KS 模型及实验效果。</td><td>摘要应具备独立可读性，涵盖研究目的、方法、结果与意义。</td></tr><tr><td><strong>引言</strong></td><td>描述人类活动识别的重要性、现有方法在相似活动区分上的困难、研究动机及本文主要贡献。</td><td>引出研究背景，指出已有方法的不足，明确研究目标。</td></tr><tr><td><strong>方法</strong></td><td>提出 XR-KS 模型结构，分为多个分类阶段，使用多个层级的特征提取与分类器组合进行细粒度识别。</td><td>写清模型架构设计逻辑，每个部分的功能及其改进点，重点突出创新性与合理性。</td></tr><tr><td><strong>实验与结果</strong></td><td>在多个公开人类活动数据集上验证模型性能，并与其他模型进行对比，证明 XR-KS 的优势。</td><td>客观呈现实验设置、指标对比结果，图表清晰展示 XR-KS 在准确率等方面的提升。</td></tr><tr><td><strong>讨论</strong></td><td>分析模型在不同场景下的表现，说明其在处理相似活动问题上的鲁棒性，并指出当前模型的局限性及未来研究方向。</td><td>解释结果的意义，结合实验分析模型优劣，同时展望可能的优化路径或拓展应用。</td></tr><tr><td><strong>结论</strong></td><td>总结 XR-KS 模型的贡献、效果与潜力，强调其对相似活动识别问题的重要意义。</td><td>精炼总结，不重复讨论部分，强化论文的研究价值与前景。</td></tr><tr><td><strong>参考文献</strong></td><td>引用了多个 HAR（人类活动识别）领域的经典文献与相关模型，包括 CNN、RNN、Two-Stream 等模型架构的研究工作。</td><td>保持格式一致、来源权威、数量适中，体现研究基础与归属。</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="总结">总结<a href="https://your-docusaurus-test-site.com/blog/00-Ahead-of-our-research-efforts#%E6%80%BB%E7%BB%93" class="hash-link" aria-label="Direct link to 总结" title="Direct link to 总结">​</a></h2>
<p>通过拆解本论文的结构与内容，我们可以看到：</p>
<ul>
<li>一篇优秀的 Research Article 应该具备清晰的问题定义、合理的方法设计、严谨的实验验证、深入的结果分析。</li>
<li>语言不求华丽，但要求逻辑严密、信息准确。</li>
<li>无论哪一部分，都需要围绕“我做了什么、为什么做、怎么做、结果如何、说明了什么”这五个核心问题来展开。</li>
</ul>
<p>📌 <strong>欢迎关注 FEMATHS 小组与山海数模，持续学习更多数学建模与科研相关知识！</strong></p>]]></content>
        <author>
            <name>Tanger</name>
            <uri>https://github.com/redhat123456</uri>
        </author>
        <category label="从入门到入土？不，是精通！科技论文完全指南" term="从入门到入土？不，是精通！科技论文完全指南"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何找到一篇合适的科技论文]]></title>
        <id>https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper</id>
        <link href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[科技论文是学者与研究人员进行学术交流的重要方式。通过阅读科技论文，不仅可以了解当前领域的研究进展，还能提升自己对复杂问题的认知能力和理解力。在学习过程中，书籍 📕、网站 🖥、期刊论文等都是常见且有效的起点资源。]]></summary>
        <content type="html"><![CDATA[<p>科技论文是学者与研究人员进行学术交流的重要方式。通过阅读科技论文，不仅可以了解当前领域的研究进展，还能提升自己对复杂问题的<strong>认知能力和理解力</strong>。在学习过程中，书籍 📕、网站 🖥、期刊论文等都是常见且有效的起点资源。</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-如何找到一篇合适的科技论文">🔍 如何找到一篇合适的科技论文<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-%E5%A6%82%E4%BD%95%E6%89%BE%E5%88%B0%E4%B8%80%E7%AF%87%E5%90%88%E9%80%82%E7%9A%84%E7%A7%91%E6%8A%80%E8%AE%BA%E6%96%87" class="hash-link" aria-label="Direct link to 🔍 如何找到一篇合适的科技论文" title="Direct link to 🔍 如何找到一篇合适的科技论文">​</a></h2>
<p>在上一节中，我们已经了解了科技论文的基本结构及其产生过程，相信你对科技论文已有初步认识。接下来，我们将学习<strong>如何寻找一篇适合阅读的科技论文</strong>。</p>
<p>找到一篇合适的论文，对于入门新领域、拓展知识视野具有重要意义。一篇好的论文能够帮助你：</p>
<ul>
<li>快速了解某个研究方向的基本概念；</li>
<li>把握领域内的研究重点与热点问题；</li>
<li>学习论文写作的结构与逻辑表达方式。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-推荐阅读开山之作">🌟 推荐阅读“开山之作”<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%E5%BC%80%E5%B1%B1%E4%B9%8B%E4%BD%9C" class="hash-link" aria-label="Direct link to 🌟 推荐阅读“开山之作”" title="Direct link to 🌟 推荐阅读“开山之作”">​</a></h3>
<p>特别推荐大家阅读某一方向的 <strong>“开山之作”</strong>，这类论文通常由该领域的先驱撰写，具有较高的学术价值。由于它们面向尚未建立共识的领域，作者往往会采用<strong>更通俗易懂的语言</strong>来描述他们的研究思路和发现，对于初学者来说极具参考价值。</p>
<p>我们小组鼓励每位成员阅读这类论文后，整理出<strong>优质的学习笔记</strong>，并发表在小组学习日志中，以便交流分享、共同成长。</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-常用论文搜索平台">📚 常用论文搜索平台：<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-%E5%B8%B8%E7%94%A8%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2%E5%B9%B3%E5%8F%B0" class="hash-link" aria-label="Direct link to 📚 常用论文搜索平台：" title="Direct link to 📚 常用论文搜索平台：">​</a></h2>
<p>你可能会需要的用到查找论文的网站</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-常用论文搜索平台-1">📚 常用论文搜索平台：<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-%E5%B8%B8%E7%94%A8%E8%AE%BA%E6%96%87%E6%90%9C%E7%B4%A2%E5%B9%B3%E5%8F%B0-1" class="hash-link" aria-label="Direct link to 📚 常用论文搜索平台：" title="Direct link to 📚 常用论文搜索平台：">​</a></h2>
<p>你可能会需要用到的查找论文的网站，这些平台涵盖了国内外权威的学术资源，适合科研初学者与进阶研究者使用。</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-google-scholar谷歌学术">🔍 Google Scholar（谷歌学术）<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-google-scholar%E8%B0%B7%E6%AD%8C%E5%AD%A6%E6%9C%AF" class="hash-link" aria-label="Direct link to 🔍 Google Scholar（谷歌学术）" title="Direct link to 🔍 Google Scholar（谷歌学术）">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/14/GIlq8Kirfvzjye1.png" alt="1.png" class="img_ev3q"></p>
<p><strong>简介</strong>：Google Scholar 是谷歌推出的学术搜索引擎，收录了全球多个数据库的论文、学位论文、书籍章节、会议论文等，支持按作者、出版物等进行检索。是学术研究中不可或缺的工具。</p>
<ul>
<li>官网：<a href="https://scholar.google.com/" target="_blank" rel="noopener noreferrer">Google Scholar:https://scholar.google.com</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-google-scholar-镜像站">🌐 Google Scholar 镜像站<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-google-scholar-%E9%95%9C%E5%83%8F%E7%AB%99" class="hash-link" aria-label="Direct link to 🌐 Google Scholar 镜像站" title="Direct link to 🌐 Google Scholar 镜像站">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/14/yY1th8b9SICzDw4.png" alt="5.png" class="img_ev3q"></p>
<p><strong>简介</strong>：由于某些网络限制，有时 Google Scholar 无法直接访问，此时可以使用镜像站点进行访问。思谋学术是较为稳定的镜像服务，界面简洁、搜索功能齐全。</p>
<ul>
<li>推荐镜像：<a href="https://ac.scmor.com/" target="_blank" rel="noopener noreferrer">思谋学术:https://ac.scmor.com/</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-arxiv">🧪 arXiv<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-arxiv" class="hash-link" aria-label="Direct link to 🧪 arXiv" title="Direct link to 🧪 arXiv">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/14/VtQ2YwNsZj6oSHR.png" alt="2.png" class="img_ev3q"></p>
<p><strong>简介</strong>：arXiv 是由康奈尔大学运营的一个开放获取的论文预印本平台，主要涵盖数学、物理、计算机科学等领域。可以第一时间获取最新研究成果，适合关注前沿技术的研究者。</p>
<ul>
<li>官网：<a href="https://arxiv.org/" target="_blank" rel="noopener noreferrer">arXiv:https://arxiv.org</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-researchgate">👥 ResearchGate<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-researchgate" class="hash-link" aria-label="Direct link to 👥 ResearchGate" title="Direct link to 👥 ResearchGate">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/14/RxkPmQb5j6ErahZ.png" alt="3.png" class="img_ev3q"></p>
<p><strong>简介</strong>：ResearchGate 是一个科研社交平台，科研人员可以上传自己的论文、阅读他人文章、参与学术讨论，甚至可以直接向作者请求全文，非常适合建立学术联系和获取资源。</p>
<ul>
<li>官网：<a href="https://www.researchgate.net/" target="_blank" rel="noopener noreferrer">ResearchGate:https://www.researchgate.net</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cnki中国知网">CNKI（中国知网）<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#cnki%E4%B8%AD%E5%9B%BD%E7%9F%A5%E7%BD%91" class="hash-link" aria-label="Direct link to CNKI（中国知网）" title="Direct link to CNKI（中国知网）">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/14/5QsYDHivAtyTOfB.png" alt="4.png" class="img_ev3q"></p>
<p><strong>简介</strong>：中国知网（CNKI）是中国最权威的中文学术文献数据库，涵盖了期刊、学位论文、会议论文、年鉴、报纸等中文文献资源，是查找中文论文和了解国内研究现状的重要平台。</p>
<ul>
<li>官网：<a href="https://www.cnki.net/" target="_blank" rel="noopener noreferrer">CNKI（中国知网）:https://www.cnki.net</a></li>
</ul>
<hr>
<blockquote>
<p>💡 如果你经常查阅论文，建议将这些网站收藏起来，并掌握基本的高级检索技巧，可以大大提升效率。</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="寻找合适的科技论文的方法">寻找合适的科技论文的方法<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#%E5%AF%BB%E6%89%BE%E5%90%88%E9%80%82%E7%9A%84%E7%A7%91%E6%8A%80%E8%AE%BA%E6%96%87%E7%9A%84%E6%96%B9%E6%B3%95" class="hash-link" aria-label="Direct link to 寻找合适的科技论文的方法" title="Direct link to 寻找合适的科技论文的方法">​</a></h2>
<p>在科研过程中，查阅论文是不可或缺的一环。一般来说，我们寻找一篇论文的动机大致可以分为以下几种情况：</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-科研遇到瓶颈寻找突破方向">1. 科研遇到瓶颈，寻找突破方向<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#1-%E7%A7%91%E7%A0%94%E9%81%87%E5%88%B0%E7%93%B6%E9%A2%88%E5%AF%BB%E6%89%BE%E7%AA%81%E7%A0%B4%E6%96%B9%E5%90%91" class="hash-link" aria-label="Direct link to 1. 科研遇到瓶颈，寻找突破方向" title="Direct link to 1. 科研遇到瓶颈，寻找突破方向">​</a></h3>
<p>当我们的研究陷入停滞、模型性能无法提升、方法效果不理想时，查阅相关领域的论文可以帮助我们了解其他研究者是如何处理类似问题的，是否有新的算法、思路或改进方向。通过横向对比和启发式学习，往往能找到新的突破口。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-初入某个领域系统了解研究现状">2. 初入某个领域，系统了解研究现状<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#2-%E5%88%9D%E5%85%A5%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%B3%BB%E7%BB%9F%E4%BA%86%E8%A7%A3%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6" class="hash-link" aria-label="Direct link to 2. 初入某个领域，系统了解研究现状" title="Direct link to 2. 初入某个领域，系统了解研究现状">​</a></h3>
<p>如果我们刚进入一个新的研究方向，需要对该领域的基础理论、主流方法、发展趋势有一个全面的认识。此时，查找综述性论文（Review）或经典文献，能够帮助我们迅速建立知识框架，避免闭门造车。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-优化已有方法寻找更好的技术路线">3. 优化已有方法，寻找更好的技术路线<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#3-%E4%BC%98%E5%8C%96%E5%B7%B2%E6%9C%89%E6%96%B9%E6%B3%95%E5%AF%BB%E6%89%BE%E6%9B%B4%E5%A5%BD%E7%9A%84%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF" class="hash-link" aria-label="Direct link to 3. 优化已有方法，寻找更好的技术路线" title="Direct link to 3. 优化已有方法，寻找更好的技术路线">​</a></h3>
<p>有时候我们已经有了初步的模型或方案，但仍希望进一步优化性能。这时可以查阅最近几年在该细分方向上的进展，了解是否有更先进的架构、损失函数、数据处理策略等。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-撰写论文或开题报告寻找文献支持">4. 撰写论文或开题报告，寻找文献支持<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#4-%E6%92%B0%E5%86%99%E8%AE%BA%E6%96%87%E6%88%96%E5%BC%80%E9%A2%98%E6%8A%A5%E5%91%8A%E5%AF%BB%E6%89%BE%E6%96%87%E7%8C%AE%E6%94%AF%E6%8C%81" class="hash-link" aria-label="Direct link to 4. 撰写论文或开题报告，寻找文献支持" title="Direct link to 4. 撰写论文或开题报告，寻找文献支持">​</a></h3>
<p>在写作过程中，我们需要引用权威文献来支撑自己的论点，或者在开题时展示已有研究基础。这就要求我们查阅相关工作，找出与我们研究课题最紧密相关的论文，并进行引用和比较分析。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="5-跟踪前沿进展把握学术动态">5. 跟踪前沿进展，把握学术动态<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#5-%E8%B7%9F%E8%B8%AA%E5%89%8D%E6%B2%BF%E8%BF%9B%E5%B1%95%E6%8A%8A%E6%8F%A1%E5%AD%A6%E6%9C%AF%E5%8A%A8%E6%80%81" class="hash-link" aria-label="Direct link to 5. 跟踪前沿进展，把握学术动态" title="Direct link to 5. 跟踪前沿进展，把握学术动态">​</a></h3>
<p>对于希望保持学术敏锐度的研究者来说，定期浏览顶会（如 NeurIPS、ICLR、CVPR 等）或预印本平台（如 arXiv）上的最新论文，有助于掌握研究趋势、技术热点和潜在研究方向。</p>
<hr>
<p>※ 📌 无论是哪种需求，选对平台和搜索关键词，掌握基本的检索技巧，都能大幅提高查阅效率。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-如何高效查找论文">🔍 如何高效查找论文？<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E6%9F%A5%E6%89%BE%E8%AE%BA%E6%96%87" class="hash-link" aria-label="Direct link to 🔍 如何高效查找论文？" title="Direct link to 🔍 如何高效查找论文？">​</a></h2>
<p>掌握一些高效的检索技巧，能够让你在浩如烟海的论文中迅速定位到真正有价值的内容。</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-1-关键词要精准--拓展">🎯 1. 关键词要“精准 + 拓展”<a href="https://your-docusaurus-test-site.com/blog/01-how-to-find-good-research-paper#-1-%E5%85%B3%E9%94%AE%E8%AF%8D%E8%A6%81%E7%B2%BE%E5%87%86--%E6%8B%93%E5%B1%95" class="hash-link" aria-label="Direct link to 🎯 1. 关键词要“精准 + 拓展”" title="Direct link to 🎯 1. 关键词要“精准 + 拓展”">​</a></h3>
<p>在搜索论文时，关键词的选择至关重要。一般建议从<strong>核心术语</strong>入手，同时结合<strong>同义词</strong>、<strong>缩写词</strong>、<strong>技术细分</strong>进行扩展。</p>
<p><strong>示例：</strong><br>
<!-- -->如果你在研究“基于图神经网络的交通预测”，你可以尝试以下关键词组合：</p>
<ul>
<li>"Graph Neural Network" + "Traffic Forecasting"</li>
<li>"GNN" + "Traffic Flow Prediction"</li>
<li>"Spatial-Temporal Graph" + "Urban Mobility"</li>
</ul>
<p>🔧 工具建议：使用 Google Scholar 时，可以用引号 <code>"..."</code> 来锁定精准短语，如 <code>"graph convolutional network"</code>。</p>
<hr>
<p>以 Google 镜像的 Sci-Hub（<a href="https://sci-hub.org.cn/" target="_blank" rel="noopener noreferrer">Sci-Hub:https://sci-hub.org.cn/</a>）为例，我们可以通过以下方式查找目标文献：</p>
<p>假设我们希望查找与图神经网络（Graph Neural Network）和交通预测（Traffic Forecasting）相关的论文，可以在图中箭头所指的搜索框中输入关键词 "Graph Neural Network" + "Traffic Forecasting"。为了提高搜索结果的相关性，我们可以在页面右侧设置检索条件，例如限定时间范围、文献类型、语言等，如下图红框内所示。</p>
<p>此外，建议大家安装一个名为 <a href="https://www.easyscholar.cc/" target="_blank" rel="noopener noreferrer">EasyScholar:https://www.easyscholar.cc/</a> 的浏览器插件，它可以在 Google 学术搜索结果中为论文添加多种标签（tag），包括期刊的影响因子（IF）、中国科学院和美国科学院的期刊分区信息、部分高校推荐分区等。这些标签有助于我们初步评估论文的质量，从而决定是否深入阅读或下载。</p>
<p>除了插件提供的标签外，我们还应关注 Google Scholar 自带的“被引用数”标签（图中波浪线所示）。引用次数往往可以反映一篇论文在该领域的影响力。对于刚开始了解某一研究方向的读者而言，优先阅读高引用量的经典文献，能够帮助快速把握该领域的研究脉络和关键问题。</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/14/BuL5zkGSZlQjwMc.png" alt="6.png" class="img_ev3q"></p>
<p>接下来，我们可以在每篇文章右侧找到相应的下载入口，或点击链接跳转至文章的官网进行查看。通常，带有 <strong>"[PDF]"</strong> 字样的条目表示该文章可以直接下载。部分文章可能是通过 <strong>arXiv</strong> 等平台发布的预印本，其内容与最终发表版本相差不大，依然具有较高的参考价值。</p>
<p>此外，还可以借助学校图书馆的资源。如果所在高校已购买相应期刊的电子数据库，便可通过校园网或 VPN 登录后直接下载所需文献。</p>
<p>希望这个示例能够帮助你更好地理解科技论文的检索与写作规范，为你的科研之路打下坚实的基础。</p>
<p>📌 <strong>欢迎关注 FEMATHS 小组与山海数模，持续学习更多数学建模与科研相关知识！</strong></p>
<p align="center"><img src="https://s2.loli.net/2025/06/12/9aDkEfKWvUMrjnm.jpg" alt="logo"></p>]]></content>
        <author>
            <name>Tanger</name>
            <uri>https://github.com/redhat123456</uri>
        </author>
        <category label="从入门到入土？不，是精通！科技论文完全指南" term="从入门到入土？不，是精通！科技论文完全指南"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何正确且高效地阅读一篇科技论文]]></title>
        <id>https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper</id>
        <link href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[如果你读到这里，或许你已经准备好去探索这个领域的规律与本质。在我们看来，认真对待每一篇论文，是科研之路的起点，更是最重要的一步。正如教育部“长江学者”特聘教授尹芝南所言：]]></summary>
        <content type="html"><![CDATA[<p>如果你读到这里，或许你已经准备好去探索这个领域的规律与本质。在我们看来，**认真对待每一篇论文，是科研之路的起点，更是最重要的一步。**正如教育部“长江学者”特聘教授尹芝南所言：</p>
<blockquote>
<p>“阅读我们的文献，是从事科学研究的<strong>基础</strong>，也是我们研究生的必修课程。”</p>
</blockquote>
<p>从头到尾逐字翻译或阅读一篇科技论文，实际上是<strong>效率最低</strong>的方式。经验丰富的科研人员通常会优先关注文章中<strong>最关键的信息</strong>，以进行快速判断其研究价值与相关性。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="正确有效的阅读一篇科技论文">正确有效的阅读一篇科技论文<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#%E6%AD%A3%E7%A1%AE%E6%9C%89%E6%95%88%E7%9A%84%E9%98%85%E8%AF%BB%E4%B8%80%E7%AF%87%E7%A7%91%E6%8A%80%E8%AE%BA%E6%96%87" class="hash-link" aria-label="Direct link to 正确有效的阅读一篇科技论文" title="Direct link to 正确有效的阅读一篇科技论文">​</a></h2>
<p>阅读一篇科技论文效率最低的方法就是从头到尾<strong>翻译</strong>。专家研究人员会从文章中较为关键的点进行查找发现。一般来说，大多数科技论文会分为五个部分，如图红色部分：</p>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/15/hD3idkFqRsogl1K.png" alt="7.png" class="img_ev3q"></p>
<ul>
<li>Abstract</li>
<li>Introduction</li>
<li>Method</li>
<li>Result</li>
<li>Discussion</li>
</ul>
<p>阅读科学文章最有效的方法是遵循以下顺序：摘要，讨论，介绍，结果，方法。原始结构和建议阅读顺序之间的差异如下：</p>
<table><thead><tr><th style="text-align:center">🍑 科技论文上的结构</th><th style="text-align:center">🍒 建议阅读时的结构</th></tr></thead><tbody><tr><td style="text-align:center">Abstract</td><td style="text-align:center">Abstract</td></tr><tr><td style="text-align:center">Introduction</td><td style="text-align:center">Discussion</td></tr><tr><td style="text-align:center">Methods</td><td style="text-align:center">Introduction</td></tr><tr><td style="text-align:center">Results</td><td style="text-align:center">Results</td></tr><tr><td style="text-align:center">Discussion</td><td style="text-align:center">Methods</td></tr></tbody></table>
<p>通过按建议的顺序阅读，您可以快速找到确定文章是否对您有用的信息。阅读每个部分后，问问自己这篇文章是否有趣并且与您的研究任务足够相关，将有助于您决定是否继续阅读它。每读完一部分内容，不如自问：“这篇论文有趣吗？与我的研究方向相关吗？”这将有效避免无效阅读。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#abstract" class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract">​</a></h3>
<p>摘要一般包括四种信息：</p>
<ul>
<li>
<p>研究的目的(这篇论文到底做了什么？)</p>
<p>第一部分通常介绍研究的目的，即这篇论文的主要目标是什么。这可能是解决某个问题、探索某个领域、验证某个假设等。</p>
</li>
<li>
<p>方法(他们是如何做到的)</p>
<p>第二部分介绍研究的方法，即作者采用了什么样的方法或者实验设计来达到目标。这可能涉及实验、数据分析、数学模型、文献回顾等。</p>
</li>
<li>
<p>结果(通过上述方法得到什么样的结果)
第三部分呈现研究的结果，即通过上述方法得到了什么样的结果或发现。这可以是定量数据、定性观察、统计分析等。</p>
</li>
<li>
<p>结论(对摘要部分的一个小总结)
最后一部分是结论，对摘要内容的一个小总结。作者通常会在这一部分中强调他们的主要发现、结果的重要性以及可能的应用或进一步研究的方向。</p>
</li>
</ul>
<p>在阅读完摘要之后，读者可以根据摘要中提供的信息和自己的兴趣、需求来决定是否继续阅读全文。如果摘要中的内容吸引了读者，并且与他们的研究领域或兴趣相关，他们可能会进一步阅读整篇论文以获取更详细的信息和结果。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h3>
<p>Introduction（引言）是论文的开篇部分，旨在引入研究的背景、目的和重要性，并概述该领域的相关研究。下面是一个按照您提供的写法，包括目的、背景、重要性和概述的示例引言：</p>
<p>引言部分通常包括以下内容：研究的目的、背景、重要性和概述。该部分提供了读者对论文主题的背景和动机的理解，以及论文的贡献和重要性的概述。</p>
<p>在本研究中，我们的目的是（论文的目的）。这一研究旨在（具体描述该目的）。通过实施该研究，我们将能够（达到的结果）。</p>
<p>在（研究领域）中，（背景信息）。然而，（描述问题、未解决的挑战或知识空白）。这表明（背景信息的重要性）。</p>
<p>因此，本研究的重要性不容忽视。通过（论文的方法或方法论），我们将能够（填补知识空白、解决问题或提供新的见解）。</p>
<p>通过阅读引言部分，读者将了解到论文的背景、目的、重要性以及后续章节的结构安排。这将帮助他们决定是否继续阅读全文，以获得更深入的理解和研究细节。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="methods">Methods<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#methods" class="hash-link" aria-label="Direct link to Methods" title="Direct link to Methods">​</a></h3>
<p>方法（Methods）部分描述了研究的具体方法、实验设计、数据收集和分析等。根据您提供的写法，下面是一个按照相同结构的示例方法部分：</p>
<p>方法部分一般包括以下内容：研究方法、实验设计、数据收集和分析。这些内容旨在介绍读者将如何进行研究以达到论文的目的。</p>
<p>本研究采用了（描述研究方法）。该方法的选择基于（理论基础、先前研究或实践经验），以确保我们能够有效地回答研究问题。</p>
<p>我们进行了（描述实验设计）。该实验设计包括（实验组和对照组、研究参与者、变量操作等）。为了保证实验的可靠性和准确性，我们采取了（对控制变量、随机分组等的措施）。</p>
<p>数据的收集涉及（数据来源、数据采集工具、测量指标等）。我们通过（描述数据收集过程）来获取关于（特定变量或现象）的定量/定性数据。</p>
<p>在数据收集完成后，我们进行了（描述数据分析方法）。我们使用了（统计方法、计算模型、质性分析等）来对数据进行分析，并提取相关结果。</p>
<p>为了确保方法的可靠性和有效性，我们进行了（对方法进行验证、实验控制等的措施）。此外，我们还采取了（伦理审查、参与者同意等）以确保研究符合道德标准和法律要求。</p>
<p>通过以上方法的选择和实施，我们能够全面、准确地回答我们的研究问题，并获得可靠的研究结果。</p>
<p>在方法部分提供了关于研究方法、实验设计、数据收集和分析的详细信息。这有助于读者了解论文的科学性和可重复性，以便更好地理解和评估研究的可靠性和结果的解释。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h3>
<p>结果（Results）部分呈现了研究的主要结果和发现。根据您提供的写法，下面是一个按照相同结构的示例结果部分：</p>
<p>结果部分一般包括以下内容：主要结果和发现的呈现、数据分析和统计结果的描述。这些内容旨在向读者传达研究所获得的具体结果。</p>
<p>我们的研究得出了以下主要结果：（描述主要结果）。这些结果表明（结果的意义和关键发现）。</p>
<p>通过对收集的数据进行（描述数据分析方法，如统计分析、质性分析等），我们发现了（详细结果描述）。具体而言，我们观察到了（结果的定量/定性信息）。</p>
<p>此外，我们进行了（对结果的验证、稳健性检查等）。通过（描述验证方法或额外分析的结果），我们确认了我们的结果的一致性和可靠性。</p>
<p>在结果部分中，我们还提供了（结果的图表、表格或图像）。这些可视化呈现了数据的趋势、关系或分布，以更直观地展示结果。</p>
<p>需要注意的是，我们还发现了一些（附加或次要结果）。尽管它们在本研究的范围内可能不是关键焦点，但它们对于（理解问题或提供背景信息）也具有一定的重要性。</p>
<p>通过结果部分的呈现，读者可以获得研究的具体结果和发现。这有助于读者对研究的有效性和可行性进行评估，并对研究的贡献和意义有更深入的理解。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="discussion">Discussion<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#discussion" class="hash-link" aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h3>
<p>讨论（Discussion）部分对研究的结果进行解释、分析，并与先前研究进行比较和讨论。以下是按照相同结构的示例讨论部分：</p>
<p>讨论部分一般包括以下内容：对结果的解释和分析、与先前研究的比较和讨论、研究的局限性和未来研究方向的探讨。这些内容旨在对研究结果进行深入分析和解读，并将其置于更广泛的研究背景中。</p>
<p>对于我们的研究结果的解释和分析，我们注意到（描述结果的关键特征或趋势）。这表明（结果的含义和可能的解释）。</p>
<p>与先前研究相比，我们的研究发现（与先前研究结果的一致性或差异）。这支持了（研究结果的可靠性或新的见解）。</p>
<p>然而，我们也要意识到本研究存在一些局限性。首先，（描述研究的局限性，如样本大小、数据来源等）。这些局限性可能对结果的解释和泛化产生一定的影响。</p>
<p>基于我们的研究结果和讨论，我们可以提出一些未来研究的方向。例如，（描述未来研究的可能性，如进一步探索特定变量、扩大样本规模等）。</p>
<p>此外，我们还应该注意到本研究的贡献和意义。我们的研究为（研究领域或问题）提供了（结果的重要洞见、方法的改进等）。</p>
<p>总体而言，通过讨论部分，我们对研究的结果进行了深入的解释和分析，并将其与先前研究进行了比较和讨论。同时，我们也承认了研究的局限性，并提出了未来研究的方向。这有助于读者更好地理解研究的贡献和限制，并启发他们对进一步研究的思考。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="总结">总结<a href="https://your-docusaurus-test-site.com/blog/02-how-to-read-research-paper#%E6%80%BB%E7%BB%93" class="hash-link" aria-label="Direct link to 总结" title="Direct link to 总结">​</a></h2>
<p><strong>认真读好每一篇论文，是科研最好的修炼方式。</strong><br>
<!-- -->比盲目扫过 100 篇无关的论文，更能真正提升你的科研水平。</p>
<p>📌 <strong>欢迎关注 FEMATHS 小组与山海数模，持续学习更多数学建模与科研相关知识！</strong></p>
<p align="center"><img src="https://s2.loli.net/2025/06/12/9aDkEfKWvUMrjnm.jpg" alt="logo"></p>]]></content>
        <author>
            <name>Tanger</name>
            <uri>https://github.com/redhat123456</uri>
        </author>
        <category label="从入门到入土？不，是精通！科技论文完全指南" term="从入门到入土？不，是精通！科技论文完全指南"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何写出一篇优秀的科技论文]]></title>
        <id>https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper</id>
        <link href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[相信看到这里的朋友，已经对一篇科研论文（Research Article）的基本结构相当熟悉了。科研工作者最常撰写的文章类型之一就是采用 IMRaD 模式 的研究论文，即包括以下几个部分：]]></summary>
        <content type="html"><![CDATA[<p>相信看到这里的朋友，已经对一篇科研论文（Research Article）的基本结构相当熟悉了。科研工作者最常撰写的文章类型之一就是采用 <strong>IMRaD 模式</strong> 的研究论文，即包括以下几个部分：</p>
<ul>
<li><strong>I – Introduction（引言）</strong></li>
<li><strong>M – Methods（方法）</strong></li>
<li><strong>R – Results（结果）</strong></li>
<li><strong>A – Abstract（摘要）</strong></li>
<li><strong>D – Discussion（讨论）</strong></li>
</ul>
<p>我将结合自己的经历，分享论文写作的一般流程。需要注意的是，<strong>论文的撰写顺序通常并不等同于其最终的排版结构</strong>。在科研实践中，写作往往是从已有的研究结果出发，逐步向前、向后延展的。</p>
<p>通常，在完成一段时间的实验或建模工作后，我们首先获得的是一组数据或研究结果。因此，写作往往是从 <strong>Results（结果）</strong> 开始，根据结果再去梳理并书写 <strong>Methods（方法）</strong>，说明这些结果是如何得到的。随后撰写 <strong>Discussion（讨论）</strong>，对结果进行分析和解释，进一步明确其意义与不足之处。</p>
<p>在此基础上，我们再回到前面，撰写 <strong>Introduction（引言）</strong>，梳理研究背景、动机、已有工作与创新点。最后撰写 <strong>Abstract（摘要）</strong>，对全文进行简洁总结。</p>
<p>因此，我们推荐的实际写作顺序如下：</p>
<table><thead><tr><th style="text-align:center">论文结构（发表顺序）</th><th style="text-align:center">实际写作建议顺序</th></tr></thead><tbody><tr><td style="text-align:center">Abstract</td><td style="text-align:center">Results</td></tr><tr><td style="text-align:center">Introduction</td><td style="text-align:center">Methods</td></tr><tr><td style="text-align:center">Methods</td><td style="text-align:center">Discussion</td></tr><tr><td style="text-align:center">Results</td><td style="text-align:center">Introduction</td></tr><tr><td style="text-align:center">Discussion</td><td style="text-align:center">Abstract</td></tr></tbody></table>
<p>采用这种写作顺序，有助于围绕核心研究结果进行清晰、有逻辑的论文构建，同时避免“边写边想”的低效写作状态。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract摘要">Abstract（摘要）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#abstract%E6%91%98%E8%A6%81" class="hash-link" aria-label="Direct link to Abstract（摘要）" title="Direct link to Abstract（摘要）">​</a></h2>
<p>摘要作为论文的开头部分，是整篇文章的核心思想浓缩表达。从读者的角度来看，摘要往往是他们接触论文的第一段文字，因此其写作质量直接影响读者是否有兴趣继续阅读下去。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="️-写作建议">✏️ 写作建议<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%EF%B8%8F-%E5%86%99%E4%BD%9C%E5%BB%BA%E8%AE%AE" class="hash-link" aria-label="Direct link to ✏️ 写作建议" title="Direct link to ✏️ 写作建议">​</a></h3>
<p>一个优秀的摘要应当做到<strong>清晰（clarity）、简洁（brevity）、明了（lucidity）</strong>，为了达成以上三个目的，我们建议使用三段式来完成摘要的书写，这个结构能够准确传达研究的关键信息，通常可以遵循以下基本结构：</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-推荐结构模板">✅ 推荐结构模板<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#-%E6%8E%A8%E8%8D%90%E7%BB%93%E6%9E%84%E6%A8%A1%E6%9D%BF" class="hash-link" aria-label="Direct link to ✅ 推荐结构模板" title="Direct link to ✅ 推荐结构模板">​</a></h3>
<ul>
<li><strong>第一段</strong>：<strong>研究背景与现状</strong>（现存问题或研究空白）</li>
<li><strong>第二段</strong>：<strong>研究方法或解决方案</strong>（本研究采用了什么方法、模型或思路）</li>
<li><strong>第三段</strong>：<strong>主要结果与结论</strong>（最终发现了什么，有哪些贡献或意义）</li>
</ul>
<p>这样的写作框架不仅能够帮助读者迅速把握论文的研究重点，也为后续的引言和正文做好铺垫。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第一段研究背景与现状现存问题或研究空白"><strong>第一段</strong>：<strong>研究背景与现状</strong>（现存问题或研究空白）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E4%B8%80%E6%AE%B5%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%E4%B8%8E%E7%8E%B0%E7%8A%B6%E7%8E%B0%E5%AD%98%E9%97%AE%E9%A2%98%E6%88%96%E7%A0%94%E7%A9%B6%E7%A9%BA%E7%99%BD" class="hash-link" aria-label="Direct link to 第一段研究背景与现状现存问题或研究空白" title="Direct link to 第一段研究背景与现状现存问题或研究空白">​</a></h4>
<p>首先是描述现状，在描述现状中一般采取先扬后抑，先肯定 XXX 技术已经取得了显著进展，再指出其仍存在的不足之处。这些不足应与我们后续研究所要解决的问题密切相关，才能确保第一段在逻辑上的连贯与必要性。在此基础上，我们还得简要介绍我们提出的模型，它跟其他模型的不同之处：</p>
<p>例如：</p>
<blockquote>
<p>Sensor-based human activity recognition is now well developed, but there are still many challenges, such as insufficient accuracy in the identification of similar activities. To overcome this issue, we collect data during similar human activities using three-axis acceleration and gyroscope sensors. We developed a model capable of classifying similar activities of human behavior, and the effectiveness and generalization capabilities of this model are evaluated. Based on the standardization and normalization of data, we consider the inherent similarities of human activity behaviors by introducing the multi-layer classifier model.</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第二段研究方法或解决方案本研究采用了什么方法模型或思路"><strong>第二段</strong>：<strong>研究方法或解决方案</strong>（本研究采用了什么方法、模型或思路）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E4%BA%8C%E6%AE%B5%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95%E6%88%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E6%9C%AC%E7%A0%94%E7%A9%B6%E9%87%87%E7%94%A8%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B9%E6%B3%95%E6%A8%A1%E5%9E%8B%E6%88%96%E6%80%9D%E8%B7%AF" class="hash-link" aria-label="Direct link to 第二段研究方法或解决方案本研究采用了什么方法模型或思路" title="Direct link to 第二段研究方法或解决方案本研究采用了什么方法模型或思路">​</a></h4>
<p>紧接着应阐明本文所采用的研究方法。该部分没有严格的结构要求，但应以<strong>准确传达方法本质</strong>为首要目标，其次才考虑语言的<strong>简洁与凝练</strong>。在确保表达准确的前提下，力求用最直接的方式让读者理解所提出方法的核心思想与实施方式。</p>
<p>例如：</p>
<blockquote>
<p>The first layer of the proposed model is a random forest model based on the XGBoost feature selection algorithm. In the second layer of this model, similar human activities are extracted by applying the kernel Fisher discriminant analysis (KFDA) with feature mapping. Then, the support vector machine (SVM) model is applied to classify similar human activities.</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第三段主要结果与结论最终发现了什么有哪些贡献或意义"><strong>第三段</strong>：<strong>主要结果与结论</strong>（最终发现了什么，有哪些贡献或意义）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E4%B8%89%E6%AE%B5%E4%B8%BB%E8%A6%81%E7%BB%93%E6%9E%9C%E4%B8%8E%E7%BB%93%E8%AE%BA%E6%9C%80%E7%BB%88%E5%8F%91%E7%8E%B0%E4%BA%86%E4%BB%80%E4%B9%88%E6%9C%89%E5%93%AA%E4%BA%9B%E8%B4%A1%E7%8C%AE%E6%88%96%E6%84%8F%E4%B9%89" class="hash-link" aria-label="Direct link to 第三段主要结果与结论最终发现了什么有哪些贡献或意义" title="Direct link to 第三段主要结果与结论最终发现了什么有哪些贡献或意义">​</a></h4>
<p>最后，我们需要介绍模型的实验结果，包括运行效率、性能表现和评估指标，并突出模型的优势。至此，整个摘要的内容就基本完成了。</p>
<p>例如：</p>
<blockquote>
<p>Our model is experimentally evaluated, and it is also applied to four benchmark datasets: UCI DSA, UCI HAR, WISDM, and IM-WSHA. The experimental results demonstrate that the proposed approach achieves recognition accuracies of 97.69%, 97.92%, 98.12%, and 90.6%, indicating excellent recognition performance. Additionally, we performed K-fold cross-validation on the random forest model and utilized ROC curves for the SVM classifier to assess the model’s generalization ability. The results indicate that our multi-layer classifier model exhibits robust generalization capabilities.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction介绍">Introduction（介绍）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#introduction%E4%BB%8B%E7%BB%8D" class="hash-link" aria-label="Direct link to Introduction（介绍）" title="Direct link to Introduction（介绍�）">​</a></h2>
<p><strong>“Introduction”</strong> 顾名思义，是整篇论文的开端，它不仅介绍研究背景与核心模型，更是作者站在专业视角，以通俗且严谨的语言引导读者理解全文核心思想的关键部分。尽管引言部分没有固定格式，但写作时仍应遵循一定的逻辑和结构，并结合不断练习和积累提升写作质量。一个好的 Introduction 能够帮助不了解你研究领域的读者，在短时间内把握论文的主题、研究意义以及你在其中的贡献。因此，Introduction 不是背景的堆砌，而是一个故事的开端。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="️-写作建议-1">✏️ 写作建议<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%EF%B8%8F-%E5%86%99%E4%BD%9C%E5%BB%BA%E8%AE%AE-1" class="hash-link" aria-label="Direct link to ✏️ 写作建议" title="Direct link to ✏️ 写作建议">​</a></h3>
<ol>
<li>
<p><strong>多阅读优秀引言</strong><br>
<!-- -->初学者应多阅读同领域内高水平论文的引言部分，特别是顶会、顶刊文章中的表达方式、背景铺陈、研究动机、贡献总结等内容。</p>
</li>
<li>
<p><strong>尝试写出“自己风格”的引言</strong><br>
<!-- -->在模仿中逐步探索出属于自己的语言风格和逻辑结构，目标是：即使读者对该研究领域并不熟悉，也能通过阅读你的 Introduction 快速掌握论文的研究动机、背景问题与研究意义。</p>
</li>
<li>
<p><strong>逻辑清晰、循序渐进</strong><br>
<!-- -->好的引言往往从 <strong>宏观背景</strong> 讲起，逐步聚焦至当前研究的具体问题，然后阐述已有工作的不足，最后说明你的工作解决了什么问题，有哪些贡献。</p>
</li>
<li>
<p><strong>参考文献的使用</strong></p>
<ul>
<li>尽量引用 <strong>近三年内的研究成果</strong>，以确保你的研究立足于当前学术前沿；</li>
<li>只有在引用奠基性理论或方法时，才建议使用三年以上甚至更久的经典文献；</li>
<li>每一条引用都应起到支撑你论述的作用，而不是堆砌数量。</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="-推荐结构模板-1">✅ 推荐结构模板<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#-%E6%8E%A8%E8%8D%90%E7%BB%93%E6%9E%84%E6%A8%A1%E6%9D%BF-1" class="hash-link" aria-label="Direct link to ✅ 推荐结构模板" title="Direct link to ✅ 推荐结构模板">​</a></h3>
<ul>
<li><strong>第一段</strong>：引入研究背景和领域发展现状；</li>
<li><strong>第二段</strong>：指出当前研究的挑战、空白或未解决问题；</li>
<li><strong>第三段</strong>：概述你的方法、思路或创新点；</li>
<li><strong>第四段</strong>：简明扼要地总结本文的主要贡献。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第一段引入研究背景和领域发展现状"><strong>第一段</strong>：引入研究背景和领域发展现状；<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E4%B8%80%E6%AE%B5%E5%BC%95%E5%85%A5%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%E5%92%8C%E9%A2%86%E5%9F%9F%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6" class="hash-link" aria-label="Direct link to 第一段引入研究背景和领域发展现状" title="Direct link to 第一段引入研究背景和领域发展现状">​</a></h4>
<p>例如：</p>
<blockquote>
<p>Human activity recognition (HAR) involves identifying various human behaviors through a series of observations of individuals and their surrounding environment [1]. HAR has been generally applied in many fields, such as security and surveillance [2], sports and fitness [3], industry and manufacturing [4], autonomous driving [5], and the references therein...</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第二段指出当前研究的挑战空白或未解决问题"><strong>第二段</strong>：指出当前研究的挑战、空白或未解决问题；<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E4%BA%8C%E6%AE%B5%E6%8C%87%E5%87%BA%E5%BD%93%E5%89%8D%E7%A0%94%E7%A9%B6%E7%9A%84%E6%8C%91%E6%88%98%E7%A9%BA%E7%99%BD%E6%88%96%E6%9C%AA%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98" class="hash-link" aria-label="Direct link to 第二段指出当前研究的挑战空白或未解决问题" title="Direct link to 第二段指出当前研究的挑战空白或未解决问题">​</a></h4>
<p>例如：</p>
<blockquote>
<p>However, a problem was identified where single-classification models can cause confusion when distinguishing similar activities, such as ascending stairs and descending stairs. In a study conducted by Jansi et al. [23], they utilized chaotic mapping to compress raw tri-axial accelerometer data and extracted 38 time-domain and frequency-domain features. These features included mean, standard deviation, root mean square, dominant frequency coefficient, spectral energy, and others. They achieved a recognition accuracy of 83.22% in human activity recognition...</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第三段概述你的方法思路或创新点"><strong>第三段</strong>：概述你的方法、思路或创新点；<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E4%B8%89%E6%AE%B5%E6%A6%82%E8%BF%B0%E4%BD%A0%E7%9A%84%E6%96%B9%E6%B3%95%E6%80%9D%E8%B7%AF%E6%88%96%E5%88%9B%E6%96%B0%E7%82%B9" class="hash-link" aria-label="Direct link to 第三段概述你的方法思路或创新点" title="Direct link to 第三段概述你的方法思路或创新点">​</a></h4>
<p>例如：</p>
<blockquote>
<p>In this paper, we propose the XR-KS (detailed description is given in Section 2) design aimed at addressing the issue of confusion between similar activities. To address the issue of similar activity feature similarity, we propose an SVM classification approach that utilizes KFDA. This approach effectively categorizes similar activities. Additionally, we conducted classification experiments on four common benchmark datasets and performed detailed analyses on these datasets. We compared our model to mainstream classification models. Experimental results demonstrate that our model exhibits excellent classification performance...</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第四段简明扼要地总结本文的主要贡献"><strong>第四段</strong>：简明扼要地总结本文的主要贡献。<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%E7%AC%AC%E5%9B%9B%E6%AE%B5%E7%AE%80%E6%98%8E%E6%89%BC%E8%A6%81%E5%9C%B0%E6%80%BB%E7%BB%93%E6%9C%AC%E6%96%87%E7%9A%84%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE" class="hash-link" aria-label="Direct link to 第四段简明扼要地总结本文的主要贡献" title="Direct link to 第四段简明扼要地总结本文的主要��贡献">​</a></h4>
<p>例如：</p>
<blockquote>
<p>The remaining sections of this paper are organized as follows: Section 2 provides a brief introduction to the work carried out in this paper, along with details about the dataset used. Section 3 conducts a basic data analysis and employs appropriate data preprocessing techniques. This section introduces our proposed approach for human motion, which is based on a multi-layer classifier. Section 4 presents the experimental setup, provides results for our proposed method on multiple datasets, and offers an analysis and discussion of these results. Finally, in Section 5, we will summarize the insights gathered from these experiments and outline future directions.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="methods-方法">Methods （方法）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#methods-%E6%96%B9%E6%B3%95" class="hash-link" aria-label="Direct link to Methods （方法）" title="Direct link to Methods （方法）">​</a></h2>
<p>方法部分同样需要广泛参考同领域的文献，了解该领域在方法描述方面的写作规范与表达方式。通常建议先阐明整体研究框架与核心思路，再逐步展开每个关键步骤的具体实现细节，以保证结构清晰、内容完整，并符合通行的学术表达习惯。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="️-写作建议-2">✏️ 写作建议<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#%EF%B8%8F-%E5%86%99%E4%BD%9C%E5%BB%BA%E8%AE%AE-2" class="hash-link" aria-label="Direct link to ✏️ 写作建议" title="Direct link to ✏️ 写作建议">​</a></h3>
<ul>
<li><strong>图文结合，提升可读性</strong><br>
<!-- -->推荐采用<strong>流程图或示意图结合文字描述</strong>的方式，更直观地展示方法步骤。例如，以下几幅图可用于概括整体流程或关键步骤的执行逻辑，有助于读者迅速理解方法框架与技术路径：</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/23/A2mhJESQIN9zKgV.jpg" alt="1.jpg" class="img_ev3q"><br>
<img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/23/rXQxM4KBhjmGEi2.jpg" alt="2.jpg" class="img_ev3q"><br>
<img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/23/bd9flHcDg5EGpeC.png" alt="3.jpg" class="img_ev3q"><br>
<img decoding="async" loading="lazy" src="https://s2.loli.net/2025/06/23/MWGm1gHEr3eFvOP.png" alt="4.png" class="img_ev3q"></p>
<ul>
<li>
<p><strong>文字描述需参考规范表达</strong><br>
<!-- -->在撰写文字说明时，应尽可能参照该领域内已发表的高质量论文，模仿其术语使用、句式结构与逻辑顺序。重点突出方法的创新点和与已有方法的区别，避免泛泛而谈。</p>
</li>
<li>
<p><strong>注意结构层次与术语统一</strong><br>
<!-- -->建议将方法部分划分为若干子模块（如“整体框架”、“预处理阶段”、“模型结构”、“训练策略”、“评估指标”等），层层推进，逻辑清晰。同时注意统一使用关键术语，避免描述不一致造成歧义。</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="results-结果">Results （结果）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#results-%E7%BB%93%E6%9E%9C" class="hash-link" aria-label="Direct link to Results （结果）" title="Direct link to Results （结果）">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="discussion-讨论">Discussion （讨论）<a href="https://your-docusaurus-test-site.com/blog/03-how-to-write-research-paper#discussion-%E8%AE%A8%E8%AE%BA" class="hash-link" aria-label="Direct link to Discussion （讨论）" title="Direct link to Discussion （讨论）">​</a></h3>]]></content>
        <author>
            <name>Tanger</name>
            <uri>https://github.com/redhat123456</uri>
        </author>
        <category label="从入门到入土？不，是精通！科技论文完全指南" term="从入门到入土？不，是精通！科技论文完全指南"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[linux操作指南之上游分析]]></title>
        <id>https://your-docusaurus-test-site.com/blog/06-生信分析1（linux操作指南）</id>
        <link href="https://your-docusaurus-test-site.com/blog/06-生信分析1（linux操作指南）"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[1. 安装linux]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-安装linux">1. 安装linux<a href="https://your-docusaurus-test-site.com/blog/06-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%901%EF%BC%88linux%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%89#1-%E5%AE%89%E8%A3%85linux" class="hash-link" aria-label="Direct link to 1. 安装linux" title="Direct link to 1. 安装linux">​</a></h2>
<p>这就不多说了，自己搞一个虚拟机，我用的是Centos7。</p>
<p>ps：如果使用的是学校集群的话，注意在修改密码中改一下自己的密码，开启后账号为：root，密码自定义（注意是暗文，你敲进去是不会显示的）结束了enter即可</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-预先安装">2. 预先安装<a href="https://your-docusaurus-test-site.com/blog/06-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%901%EF%BC%88linux%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%89#2-%E9%A2%84%E5%85%88%E5%AE%89%E8%A3%85" class="hash-link" aria-label="Direct link to 2. 预先安装" title="Direct link to 2. 预先安装">​</a></h2>
<p>首先要安装anaconda，为了不污染环境</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- 安装linux安装包（如果报错自己去anaconda网站找地址）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wget https://repo.anaconda.com/archive/Anaconda3-2023.07-Linux-x86_64.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 解压anaconda，后面的就是刚刚安装好的名字</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bash Anaconda3-2023.07-Linux-x86_64.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 更新环境变量</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source ~/.bashrc</span><br></span></code></pre></div></div>
<p>至此，anaconda安装完成。我们再创建一个环境，专门用于生信分析</p>
<p>tips：anaconda教程请查看TensorFlow1教程，需要包含的步骤为：</p>
<ol>
<li>create一个虚拟环境</li>
<li>设置镜像中除了最后一个，其他都跑</li>
<li>下载fastqc</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-安装分析软件">3. 安装分析软件<a href="https://your-docusaurus-test-site.com/blog/06-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%901%EF%BC%88linux%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%89#3-%E5%AE%89%E8%A3%85%E5%88%86%E6%9E%90%E8%BD%AF%E4%BB%B6" class="hash-link" aria-label="Direct link to 3. 安装��分析软件" title="Direct link to 3. 安装分析软件">​</a></h2>
<p>这些软件因人而异，不一定需要全下载</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- 最主要的分析fast格式的软件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda install fastqc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 有时候fastq不止一个文件，联合分析</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda install multigc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 高通量测序数据中去除接头序列和其他不需要的序列</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda install -c bioconda cutadapt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 用于将sra转化为fastq文件的脚本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda install sra-tools</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>cellranger单独拎出来讲，这个软件应该使用到的频率比较大</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- 下载安装包（上官网找，复制粘贴即可，如果报错和anaconda一样）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wget -O cellranger-8.0.1.tar.gz "https://cf.10xgenomics.com/releases/cell-exp/cellranger-8.0.1.tar.gz?Expires=1724187641&amp;Key-Pair-Id=APKAI7S6A5RYOXBWRPDA&amp;Signature=Nym8cB6esJ3Zk7nueAU7BG3hhF2IZBp9FpD4OE5gW0a7C-m4ob7lChp0W-j7ydgnEBYafZ~igPGR~DzUq4CxsXS4XwkENuKhwn7Xr7RbdO~wGGh03fWzYyYt~Y7FK~V~73DzJEplvcls0p~KdbcQYvb7NflwtO9YMY~FnO4fB2VmFf5QBMdpXbPubMG~jNWE58ki7zr6ilsMGAfEnI6Po4cpZKKe1VCN7zJeipUKqS9qj~jGRpIGjHV9abluAPeodE-zCk0F-bsMpXSx6x~avzQfrN6ViJoRNEBemaB7anzMOTJ7L3XEP~QprOaJKKobFWZBGz4MBXokQBxByAZObQ__"</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 解压，xyz为版本号</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tar -xzvf cellranger-x.y.z.tar.gz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 配置环境变量</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source ~/.bashrc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 查看是否成功</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cellranger --version</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-------如果失败，进入到vim中写，vim对于初学者来说比较复杂，建议认真读教程，不要多做也不要少做-------</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 1. 打开文件</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vim ~/.bashrc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 2. 进入编辑模式 ，按键盘i键</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 3. 添加cellranger的路径，将光标移到最后一行，添加内容（-8.0.1是cellranger文件夹的名字，看自己下载的名字是什么）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export PATH=$PATH:/root/cellranger-8.0.1/bin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 4. 先按Esc退出编辑模式，然后输入:wq，最后按enter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 5. 重加载</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source ~/.bashrc</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 6.查看是否成功</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cellranger --version</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-测序数据质量评估">4. 测序数据质量评估<a href="https://your-docusaurus-test-site.com/blog/06-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%901%EF%BC%88linux%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%89#4-%E6%B5%8B%E5%BA%8F%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0" class="hash-link" aria-label="Direct link to 4. 测序数据质量评估" title="Direct link to 4. 测序数据质量评估">​</a></h2>
<p>ok，开始正式的质量评估</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="41-cutadapt">4.1 cutadapt<a href="https://your-docusaurus-test-site.com/blog/06-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%901%EF%BC%88linux%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%89#41-cutadapt" class="hash-link" aria-label="Direct link to 4.1 cutadapt" title="Direct link to 4.1 cutadapt">​</a></h4>
<p><strong>去除接头序列</strong>：</p>
<p>在测序过程中，接头序列会附加到 DNA 或 RNA 片段的两端。<code>cutadapt</code> 可以从测序读段（reads）中识别并去除这些接头序列。</p>
<p><strong>去除低质量碱基</strong>：</p>
<p>除了接头序列，还可以去除位于读段两端的低质量碱基，保证下游分析中使用的是高质量的数据。</p>
<p><strong>处理指定长度的序列</strong>：</p>
<p>可以设置参数来过滤特定长度的序列，比如去除过短或过长的序列，这有助于控制下游数据分析中的数据质量。</p>
<p><strong>双端测序数据处理</strong>：</p>
<p><code>cutadapt</code> 支持双端测序数据，可以同时处理两端的序列，并保持双端读段的配对关系。</p>
<p>ps：在做cutadapt之前，首先是需要通过fastqc的质控报告观测是否需要去除的，具体在Adapter Content这一栏中，如果是打钩就不需要，打叉的话分情况讨论：</p>
<ol>
<li>数据数据集上down下来的数据一般会显示测序的平台是啥，这时候使用平台默认的就ok了</li>
<li>自己的数据也知道用的测序平台是啥，同上</li>
</ol>
<p>如果用的是illumina的话，read1为AGATCGGAAGAGC，read2为AATGATACGGCGACC。如果用的是其他测序平台的话，建议翻看手册查询（一般都会给出的）</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- 检查接头序列</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cutadapt --detect-adapters -o /path/to/trimmed_output.fq /path/to/input.fq</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 本数据为read2（illumina），read1同理，反正都要处理</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cutadapt -a AGATCGGAAGAGC -q 20 --minimum-length 50 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         -j 4 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         -o /root/rowdata/Rhesus-Liver-1_L1_2_trimmed.fq.gz \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         /root/rowdata/Rhesus-Liver-1_L1_2.fq.gz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>在预处理完数据之后，就可以通过fastqc可视化数据质量了，可以百度网页结果</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">fastqc -t 4 -o ~/fastqc_output /root/rowdata/Rhesus-Liver-1_L1_2.fq.gz</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="42-cellranger">4.2 cellranger<a href="https://your-docusaurus-test-site.com/blog/06-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%901%EF%BC%88linux%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97%EF%BC%89#42-cellranger" class="hash-link" aria-label="Direct link to 4.2 cellranger" title="Direct link to 4.2 cellranger">​</a></h4>
<ol>
<li><strong>创建自定义参考基因组</strong></li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- 这一步是因为我的gtf中，Curated Genomic包含空格，因此需要替换为Curated_Genomic</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sed 's/Curated Genomic/Curated_Genomic/g' GCF_003339765.1_Mmul_10_genomic.gtf &gt; fixed_GCF_003339765.1_Mmul_10_genomic.gtf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 设置核心数，按照自己的配置来定，一般max-1就ok了</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export CELLRANGER_NUM_THREADS=15</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- 如果没有处理过gtf的话，原名就ok，如果sed了，那就改成自己处理后的gtf文件名，output-dir为文件输出的位置，可自定义</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cellranger mkref --genome=mmul_ref \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--fasta=/root/compare/GCF_003339765.1_Mmul_10_genomic.fna \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--genes=/root/compare/fixed_GCF_003339765.1_Mmul_10_genomic.gtf \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--output-dir=/root/compare/mmul_ref</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<ol start="2">
<li><strong>使用 <code>cellranger count</code> 进行比对和分析</strong></li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cellranger count \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --id=liver_analysis \  # 输出文件夹的名称</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --transcriptome=/root/compare/mmul_ref \  # 参考基因组路径</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --fastqs=/root/liver_PE \  # 存放FASTQ文件的目录</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --sample=sample_name \  # 样本名称，一般为liver_PE-1或liver_PE-2这样的</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --expect-cells=1000 \  # 预期细胞数，可根据实验设定调整（也可不用，默认1k）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --localcores=16 \  # 使用的核心数</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --localmem=180  # 使用的内存（GB）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --create-bam=true  # 通常默认，但是当发生该参数缺少的报错时可以显式添加</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>需要注意的是，如果我有liver_PE-1和liver_PE-2，那需要分别跑两次，然后对其进行合并</p>
<ol start="3">
<li><strong>使用<code>cellranger arr</code>对结果进行合并</strong></li>
</ol>
<p>首先船舰csv文件，列出每个样本的<code>molecule_info.h5</code> 文件路径，内容如下：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">library_id,molecule_h5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">liver_PE-1,/root/liver_analysis1/outs/molecule_info.h5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">liver_PE-2,/root/liver_analysis2/outs/molecule_info.h5</span><br></span></code></pre></div></div>
<p>随后对其进行合并</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cellranger aggr \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --id=liver_combined_analysis \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --csv=aggregation.csv \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --normalize=mapped \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --localcores=16 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --localmem=180</span><br></span></code></pre></div></div>
<p>生成一个新的文件夹 <code>liver_combined_analysis</code>，其中包含合并后的 <code>filtered_feature_bc_matrix</code> 文件夹。</p>
<hr>
<p>ps:在此推荐两个小工具了，下载和安装就百度吧，基本上都有教程的</p>
<ol>
<li>winscp用于本地到服务器上的文件传输（可视化，很方便，并且也可以在这里增删改查文件）</li>
<li>finalshell可以复制粘贴代码（学校集群cv不了），并且旁边有当前内存，储存空间，cpu占用等有用的信息</li>
</ol>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[质控与聚类]]></title>
        <id>https://your-docusaurus-test-site.com/blog/07-生信分析2（质控与聚类）</id>
        <link href="https://your-docusaurus-test-site.com/blog/07-生信分析2（质控与聚类）"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[1. 测出数据部分]]></summary>
        <content type="html"><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-测出数据部分">1. 测出数据部分<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#1-%E6%B5%8B%E5%87%BA%E6%95%B0%E6%8D%AE%E9%83%A8%E5%88%86" class="hash-link" aria-label="Direct link to 1. 测出数据部分" title="Direct link to 1. 测出数据部分">​</a></h2>
<p>在通过前文的处理之后，我们得到了两个输出文件，分别为raw_feature_bc_matrix和filter_feature_bc_matrix。前者为原始数据，后者为cellranger经过自己处理后的数据，后续的分析会基于filter_feature_bc_matrix文件夹（上游比对分析产生的三个文件）。文件夹目录如下</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">--filter_feature_bc_matrix</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----barcodes.tsv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----features.tsv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">----matrix.mtx</span><br></span></code></pre></div></div>
<p>逐一解释：</p>
<p>**barcodes.tsv：**细胞标签</p>
<p>**features.tsv：**基因ID</p>
<p>**matrix.mtx：**表达数据</p>
<p>后续我们会使用seurat（R语言）进行分析</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-质量控制">2. 质量控制<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#2-%E8%B4%A8%E9%87%8F%E6%8E%A7%E5%88%B6" class="hash-link" aria-label="Direct link to 2. 质量控制" title="Direct link to 2. 质量控制">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-数据预处理">2.1 数据预处理<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#21-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" class="hash-link" aria-label="Direct link to 2.1 数据预处理" title="Direct link to 2.1 数据预处理">​</a></h3>
<p>导入包的过程忽略了</p>
<p>首先我们先加载数据集，得到的数据应该如下所示：</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/1.png" alt="" class="img_ev3q"></p>
<p>这是一个稀疏矩阵（<strong>这很重要，在后续分析中稀疏矩阵占用内存会比疏密矩阵小很多，不然在大数据集的情况下内存会爆炸</strong>）；行代表基因（或者特征，取决于数据类型）；列代表细胞。值代表特定细胞中某个基因的原始 UMI（Unique Molecular Identifier）计数。</p>
<p>接着，我们需要先进行初步的筛选并查看数据分布，小提琴图与箱线图都是常用的办法，在此我们选择最为常用的小提琴图（更明了）。默认筛选条件为：</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">if(表达基因数&lt;200 or 表达基因&lt;3个细胞)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	delete</span><br></span></code></pre></div></div>
<p>可能来自一定比例的低质量细胞（比如细胞破碎造成细胞质RNA流失）。由于线粒体比单个的转录本大，不容易在破碎的细胞膜中漏出，从而导致测序结果显示线粒体基因的比例在细胞内占比过高。因此，质量控制这一步的目的就是把这些低质量的细胞去除掉。最后计算线粒体基因占所有基因比例后，做小提琴图</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/2.png" alt="" class="img_ev3q"></p>
<p>我们也可以绘制散点图，查看线粒体和基因数异常分布的数据点</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/3.png" alt="" class="img_ev3q"></p>
<p>得到初步的分布情况之后，我们就需要根据可视化的情况进行筛选了，在此再进行条件过滤</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">if(表达基因数目&lt;200 or 表达基因数目&gt;5000)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	delete</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if(线粒体基因占比 &gt; 20%)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	delete</span><br></span></code></pre></div></div>
<p>这里的阈值都需要自己做条件，请按照可视化后的结果自己调整，举个栗子，心肌细胞，本身就含有较多的线粒体，可以根据实际情况适当的调整阈值</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="高变异基因">高变异基因<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#%E9%AB%98%E5%8F%98%E5%BC%82%E5%9F%BA%E5%9B%A0" class="hash-link" aria-label="Direct link to 高变异基因" title="Direct link to 高变异基因">​</a></h3>
<p>这步的筛选可以理解为：如果有些基因的表达量都非常高并且每个细胞中表达水平十分相似，那就说明这一些基因的变异度很低，无用可以筛除。高变异基因的筛选方法有：基于方差（vst），基于离散程度，基于负二项分布，基于熵值等等。vst是较为常用的办法。在此默认我们保留2000个基因，得到结果如下</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/4.png" alt="" class="img_ev3q"></p>
<p>可以看到，我们对标准化与未标准化的数据都进行了比较，标准化后的数据表现更好，使用log1p，即表达量的对数加1；使用其他办法如标准化到10000也是可以的</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-聚类分析">2. 聚类分析<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#2-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90" class="hash-link" aria-label="Direct link to 2. 聚类分析" title="Direct link to 2. 聚类分析">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-降维">2.1 降维<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#21-%E9%99%8D%E7%BB%B4" class="hash-link" aria-label="Direct link to 2.1 降维" title="Direct link to 2.1 降维">​</a></h3>
<p>在进行聚类之前，我们需要首先对数据进行降维，降维之后可以将很多不必要的特征删除。PCA是最为常用的办法，我们可以通过前文筛选出的2000个变量进行降维</p>
<p>在降维之后，我们可以查看PC_1与PC_2中单个细胞之间表现出相关性</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/5.png" alt="" class="img_ev3q"></p>
<p>也可以查看在两个维度中，数据的分布情况。以主成分PC1、PC2为例，展示主成分分析得到的细胞分布图。</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/6.png" alt="" class="img_ev3q"></p>
<p>最后画出碎石图，这<strong>直接决定了后续我们聚类所采用的参数</strong></p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/7.png" alt="" class="img_ev3q"></p>
<p><strong>如何选择参数？</strong></p>
<p>很简单，寻找拐点位置，并且这个拐点（比如说dim=20）的解释量必须要大于90%。</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">for dim in range(50):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">	if dim_for_exp &gt; 90%:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">		break</span><br></span></code></pre></div></div>
<p>tips：有人在论文中做过实验，一般我们取30左右进行，其实25-35都不会很影响后续的分析，但这个<strong>必须按照自己画出来的碎石图进行判断</strong></p>
<p>当然，也可以通过Jackstraw分析判断选取成分数量</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/8.png" alt="" class="img_ev3q"></p>
<p>只要高于虚线，dim都是可取的，本文由于电脑配置原因跑起来太慢了，因此只画了20个==</p>
<p>也可以绘制维度热力图，探索数据集中异质性的主要来源（主打一个图多好看）</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/9.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-聚类">2.2 聚类<a href="https://your-docusaurus-test-site.com/blog/07-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%902%EF%BC%88%E8%B4%A8%E6%8E%A7%E4%B8%8E%E8%81%9A%E7%B1%BB%EF%BC%89#22-%E8%81%9A%E7%B1%BB" class="hash-link" aria-label="Direct link to 2.2 聚类" title="Direct link to 2.2 聚类">​</a></h3>
<p>目前，主流的聚类办法有两种，分别为umap和t-sne。前者聚的更紧凑，后者</p>
<p>Umap聚类效果更为紧凑，簇间近且边缘轮廓也较为靠近</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/10.png" alt="" class="img_ev3q"></p>
<p>T-sne相反</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/11.png" alt="" class="img_ev3q"></p>
<p>你以为这就结束了？大错特错！聚类有很多重要参数，不同的参数聚出来的效果是截然不同的。接下来依次说明：</p>
<p>Neighbors：单个细胞认为自己邻居数量的半径，这个参数可以由上文的pca得出</p>
<p>ClustersNumber：簇数量，可以通过leiden算法得出，其中的resolution也需要自己手动控制</p>
<p><strong>理论上来说，簇数量是由真实世界决定的，比如说表皮细胞，有多少个就聚多少个簇，上文的所有办法都是为这个服务</strong><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/13.png" alt="" class="img_ev3q"></p>
<p>当然，在前期我们不知道数量的时候，可以通过决策树来决定resolution的值到底是多少，以次先做一个大致的观察。原则是不要交叉，交叉就暂停。整一张抽象的图，按照这样的话就取0.2</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/12.png" alt="" class="img_ev3q"></p>
<hr>
<p>需要代码直接联系本人哦，下方评论区or
邮箱<!-- -->:zhouqijia1110<!-- -->@gmail.com</p>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[差异基因与细胞标注]]></title>
        <id>https://your-docusaurus-test-site.com/blog/08-生信分析3（差异基因与细胞标注）</id>
        <link href="https://your-docusaurus-test-site.com/blog/08-生信分析3（差异基因与细胞标注）"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[在单细胞RNA测序分析中，聚类之后筛选差异基因的主要目的是为了深入理解不同细胞群体之间的生物学差异。首先先看我们筛选出来的数据并对其进行解释]]></summary>
        <content type="html"><![CDATA[<p>在单细胞RNA测序分析中，聚类之后筛选差异基因的主要目的是为了深入理解不同细胞群体之间的生物学差异。首先先看我们筛选出来的数据并对其进行解释</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/1-1.png" alt="" class="img_ev3q"></p>
<p>**p_val：**基因表达量差异P值（一般不看这个）</p>
<p>**p_val_adj：**校正后的P值（一般看这个）</p>
<p>**avg_log2FC：**基因在该细胞簇中与其他细胞簇表达量差异倍数的log值，一般大于2是最好的效果，说明差异很大</p>
<p>**pct.1：**在该细胞簇中表达该基因的细胞数量占比</p>
<p>**pct.2：**在其他细胞簇中表达该基因的细胞数量占比平均值</p>
<p>**cluster：**在哪一类簇中</p>
<p>**gene：**名字</p>
<p>**myroc：**roc评分，范围从[0,1] ，越大越好</p>
<hr>
<p>我们做差异基因检查的目的是什么呢？</p>
<ol>
<li><strong>验证聚类结果</strong></li>
</ol>
<p>聚类过程将细胞分为不同的群体，但这些群体是否具有生物学意义需要进一步验证。筛选出差异基因可以帮助确定这些聚类是否合理。并且，如果在不同的聚类之间找到显著差异的基因，说明这些群体之间可能存在生物学差异，证明聚类是合理的。</p>
<ol start="2">
<li><strong>标记细胞群体</strong></li>
</ol>
<p>放在后文讲，这就是细胞标注</p>
<ol start="3">
<li><strong>下游分析</strong></li>
</ol>
<p>这些基因是下游基因的基础（GO分析，KEGG，拟时序，cell-cell communication等）</p>
<ol start="4">
<li><strong>优化聚类</strong></li>
</ol>
<p>通过筛选差异基因，可以对初步聚类结果进行评估</p>
<hr>
<p>如何对差异基因进行评估？首先，前者的roc评分可以作为一个依据，其次，可以通过可视化进行观察</p>
<p>该基因在其他簇中的分布情况（小提琴图与聚类特征标注图）</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/2-1.png" alt="" class="img_ev3q"></p>
<p>通过小提琴图可以观测出，ITBG1这个基因其实在每个簇中都有，<strong>差异基因是通过比较其他簇得出的</strong>，这就说明其实这个基因的差异性不是很明显，<strong>相反RTKN2更有差异性</strong>，我们做到差异基因这一步的时候，必须要有该簇的分布与其他簇不同的结果，这样后续细胞标记出的结果也会更好</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/3-1.png" alt="" class="img_ev3q"></p>
<p>特征可视化也可以看出，ITGB1在整张图上都是有的，这就说明他的差异性并不是很显著</p>
<h1>4. 细胞标注</h1>
<p>这步很重要，并且这和聚类效果息息相关，在细胞标注中，分为singleR自动标注与手动标注两种，后者的精确值是最高的，所以如果没有特殊情况的话，强烈要求使用手动标注。</p>
<p>手动标注同时需要十分强大的生物知识（我不会QAQ）。具体来说步骤如下：</p>
<ol>
<li>查看差异基因后，查询数据库和文献。文献先不提了，数据库可以使用这三个：Cellmarker，singleCellBase， HCA， MCA。数据库中包含人，鼠，猴等等，其中人的最多。</li>
<li>评估可以使用交叉验证，即使用多个标志基因组合进行注释并进行交叉对比</li>
<li>对于某一类的细胞群体，我们还可以手动为每个细胞群体赋予一个标签，如“CD4+ T细胞”、“中性粒细胞”等</li>
</ol>
<hr>
<p><strong>tips：对于聚类来说，我们可以先对其进行一个大的聚类，将细胞大群先注释出来，随后在细化聚类</strong></p>
<hr>
<p>经验：log2FC的本质就是簇中对比差异性，越大就越说明与其他簇的分布情况不同，相对应的，这在找marker的时候也更方便，而p值只是一个假设检验的值。所以在寻找差异基因的筛选条件时，优先log2FC（云经验，哥们也没做过细胞标注）</p>
<hr>
<p>需要代码直接联系本人哦，下方评论区or
邮箱<!-- -->:zhouqijia1110<!-- -->@gmail.com</p>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[富集分析]]></title>
        <id>https://your-docusaurus-test-site.com/blog/09-生信分析4（富集分析）</id>
        <link href="https://your-docusaurus-test-site.com/blog/09-生信分析4（富集分析）"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[通过前文我们可以提取出差异基因，然而差异基因的数量较多，对其进行分析会十分冗长，因此我们可以采取富集分析的方式进行归类。富集的意思是表示差异基因或者差异物质中注释到某个代谢通路的基因或者物质数目在所有差异基因或者物质中的比例显著大于背景基因或物质中注释到某个代谢通路的基因或物质数目在所有背景基因或者物质中的比例。简而言之一句话概括：该差异基因在特定的通路上占比很大]]></summary>
        <content type="html"><![CDATA[<p>通过前文我们可以提取出差异基因，然而差异基因的数量较多，对其进行分析会十分冗长，因此我们可以采取富集分析的方式进行归类。富集的意思是表示差异基因或者差异物质中注释到某个代谢通路的基因或者物质数目在所有差异基因或者物质中的比例显著大于背景基因或物质中注释到某个代谢通路的基因或物质数目在所有背景基因或者物质中的比例。简而言之一句话概括：<strong>该差异基因在特定的通路上占比很大</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="51-go富集分析">5.1 GO富集分析<a href="https://your-docusaurus-test-site.com/blog/09-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%904%EF%BC%88%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%EF%BC%89#51-go%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90" class="hash-link" aria-label="Direct link to 5.1 GO富集分析" title="Direct link to 5.1 GO富集分析">​</a></h2>
<p>主要用来看基因的三个方面，分别是分子功能、细胞组分、参与的生物过程。</p>
<p>举例，铁离子结合的GO term是GO:0005506，如果我们对所得到的差异基因进行GO富集分析后得到该term富集，则我们可以认为我们所研究的现象可能与铁离子结合有关系</p>
<p>进行go分析时，可以得到如下数据：</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/4-1.png" alt="" class="img_ev3q"></p>
<p>参数解释：</p>
<p><strong>category：</strong> Gene Ontology数据库中唯一的标号信息</p>
<p>**over_represented_pvalue：**富集分析P值，P 值越小越显著</p>
<p><strong>under_represented_pvalue：</strong></p>
<p>**numDEInCat：**该功能类下的差异基因数目</p>
<p>**numInCat：**该功能类下的基因数目</p>
<p>**term：**Gene Ontology功能的描述信息</p>
<p>**ontology：**该GO的类别(CC，细胞组分；BP，生物进程；MF，分子功能)。</p>
<p>接着，还可以可视化DAG图，分支代表包含关系，从上至下所定义的功能范围越来越小，一般选取GO富集分析的结果前5位作为有向无环图的主节点，颜色的深浅代表富集程度。概括的说， 可以分析GO terms在富集分析中是否显著，并且terms是如何相互关联的</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/5-1.png" alt="" class="img_ev3q"></p>
<p>最后，也可以通过柱状图将ontology进行分类，以柱状图呈现出来</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/6-1.png" alt="" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/7-1.png" alt="" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="52-kegg分析">5.2 KEGG分析<a href="https://your-docusaurus-test-site.com/blog/09-%E7%94%9F%E4%BF%A1%E5%88%86%E6%9E%904%EF%BC%88%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%EF%BC%89#52-kegg%E5%88%86%E6%9E%90" class="hash-link" aria-label="Direct link to 5.2 KEGG分析" title="Direct link to 5.2 KEGG分析">​</a></h2>
<p>在生物体内，不同基因相互协调行使其生物学功能，通过Pathway显著性富集能确定差异表达基因参与的最主要生化代谢途径和信号转导途径。KEGG（Kyoto Encyclopedia of Genes and Genomes）是有关Pathway的主要公共数据库(Kanehisa,2008）。Pathway显著性富集分析以KEGG Pathway为单位，应用超几何检验，找出与整个基因组背景相比，在差异表达基因中显著性富集的Pathway</p>
<p>通过KEGG分析后，我们可以得出如下表格（注意：使用enrichKEGG后传入的是一个对象，建议转为数据框，方便后续的作图与分析）</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/8-1.png" alt="" class="img_ev3q"></p>
<p>表格有些大，主要是geneID太长了，分别解释各字段含义：</p>
<p>**ID：**KEGG的PATHWAY数据库中途径标识</p>
<p>**Description：**该通路的描述</p>
<p>**GeneRAatio：**富集到该通路里的差异基因数/全部可以富集到KEGG里的差异基因数，比例越高说明越富集</p>
<p>**BgRatio：**该通路的全部基因数/该物种全部有KEGG信息的基因数</p>
<p>**pvalue：**p值，不过多解释了</p>
<p>**p.adjust：**矫校正过的p值</p>
<p>**qvalue：**q值</p>
<p>**geneID：**富集到该通路里的基因的名称</p>
<p>**Count：**富集到该通路中的差异基因的数目</p>
<p>接着，我们就可以画出点图与柱状图了。先说前者，这个只需要一行代码就行</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/9-1.png" alt="" class="img_ev3q"></p>
<p>在绘制柱状图的时候，同时还需要注意柱子颜色的分类。在其他资料中观察到他是按照通路类别进行分类的，一共有如下七种：</p>
<ul>
<li><strong>Metabolism（代谢）</strong></li>
<li><strong>Genetic Information Processing（遗传信息处理）</strong></li>
<li><strong>Environmental Information Processing（环境信息处理）</strong></li>
<li><strong>Cellular Processes（细胞过程）</strong></li>
<li><strong>Organismal Systems（有机体系统）</strong></li>
<li><strong>Human Diseases（人类疾病）</strong></li>
<li><strong>Drug Development（药物开发）</strong></li>
</ul>
<p>我们可以通过KEGG官网，以id为key进行辨别</p>
<ol>
<li>登录<a href="https://www.genome.jp/kegg/pathway.html" target="_blank" rel="noopener noreferrer">KEGG PATHWAY Database (genome.jp)</a></li>
<li>输入id</li>
<li>查看类型后手动标注</li>
</ol>
<p>以两个我瞎编的为例，柱状图最后应该长这样
<img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/10-1.png" alt="" class="img_ev3q"></p>
<h1>批次效应</h1>
<p>用于多样本整合时才需要，不过多赘述（因为我没有）</p>
<h1>5.3 Reactome</h1>
<p>这个其实和前面两个是一样的，区别仅仅是换了一个数据库</p>
<div class="language-R language-r codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-r codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># 使用ReactomePA进行通路富集分析（只有human）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">reactome_results &lt;- enrichPathway(gene = entrez_genes, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                  organism = "human", </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                  pvalueCutoff = 0.05, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                  readable = TRUE)</span><br></span></code></pre></div></div>
<p>我是做的猴子，这个数据库听说只有人鼠，具体还有什么可以自己百度一下</p>
<h1>5.4 GSEA</h1>
<p>这块内容其实和前文的GO与KEGG分析相同，主要不同在于GO富集分析是先筛选差异基因，再判断差异基因在哪些注释的通路存在富集；这涉及到阈值的设定，存在一定主观性并且只能用于表达变化较大的基因，即我们定义的显著差异基因。GSEA则不局限于差异基因，从基因集的富集角度出发，理论上更容易囊括细微但协调性的变化对生物通路的影响。</p>
<p>图表与上文是一样的，不过多赘述</p>
<p>（参考自<a href="https://blog.csdn.net/kanghua_du/article/details/136007496" target="_blank" rel="noopener noreferrer">一文掌握单基因GSEA富集分析 | gseaGO and gseaKEGG-CSDN博客</a>）</p>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PPI分析]]></title>
        <id>https://your-docusaurus-test-site.com/blog/10-生信分析5（PPI与FT分析）</id>
        <link href="https://your-docusaurus-test-site.com/blog/10-生信分析5（PPI与FT分析）"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[这两块代码含量都比较少，大部分通过在线分析就可以出结果]]></summary>
        <content type="html"><![CDATA[<p>这两块代码含量都比较少，大部分通过在线分析就可以出结果</p>
<p>构建差异表达基因编码的蛋白质之间的相互作用网络，识别关键调控蛋白质或蛋白质复合物。</p>
<p>输出的是PPI网络图及其分析结果，发现核心蛋白质。</p>
<p>在线分析网站：<a href="https://string-db.org/cgi/network?taskId=bcsvtUNgt2ym&amp;sessionId=bcOtOSQeQUGK" target="_blank" rel="noopener noreferrer">356 items (Macaca mulatta) - STRING interaction network (string-db.org)</a></p>
<p>可选选项：</p>
<ol>
<li>隐藏无关联节点</li>
<li>节点多少可由score设置</li>
<li>保存为tsv文件（as tabular test output），进入到cytoscape进行美化</li>
<li>多个选Multiple proteins；单个选Protein by name</li>
</ol>
<h1>8 TF分析</h1>
<p>通过转录因子分析，识别在细胞亚群中可能调控这些差异表达基因的关键转录因子。输出潜在的调控转录因子及其靶基因网络。
推荐网站：BART，以高变基因为key（但是分析速度很慢，暂且未找到理由，可能是因为我的数据量太大，也有可能是因为TF分析本身就很慢（计算相关性网络非常缓慢，我用的是R语言，读者如果有条件的话可以用python进行计算））</p>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[拟时序分析]]></title>
        <id>https://your-docusaurus-test-site.com/blog/11-生信分析6（拟时序分析）</id>
        <link href="https://your-docusaurus-test-site.com/blog/11-生信分析6（拟时序分析）"/>
        <updated>2025-06-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[在进行了聚类之后，其实各细胞是否具有同种生存状态是未知的。拟时序分析的目的就在于将细胞分为不同的分支，将各点（细胞）体现在不同的时间坐标中，从而了解各细胞的状态定位]]></summary>
        <content type="html"><![CDATA[<p>在进行了聚类之后，其实各细胞是否具有同种生存状态是未知的。拟时序分析的目的就在于将细胞分为不同的分支，将各点（细胞）体现在不同的时间坐标中，从而了解各细胞的状态定位</p>
<p>在做拟时序分析的时候，采取的是机器学习方法（无监督和有监督），因此需要一定的生物学知识对图标进行判断，图中主要是为了表达细胞之间（簇）表达谱系的连续性，因此方向未必与现实情况相同（需要在代码中加入reserve）</p>
<p>举个例子：B细胞不会分化为NK细胞，但在图中就会如此，这就是reserve的作用</p>
<p>本文主要采取无监督的方法进行分析</p>
<hr>
<p>tips：无监督就是没有真实数据，有监督就是包含一定的真实数据</p>
<ul>
<li><strong>无监督数据</strong>：常见的如单细胞 RNA 测序数据，在特定的发育阶段采集了样本，但不确定细胞的确切时间顺序。</li>
<li><strong>有监督数据</strong>：例如药物处理实验，在不同时间点采集了单细胞样本，记录了每个样本的处理时间，通过这些时间点信息可以进行有监督的拟时序分析。</li>
</ul>
<hr>
<p>首先，使用monocol2创建CellDataset对象后，就有了拟时分析结果的可视化，我们可以将其分为：</p>
<p>state状态：</p>
<p>代表了细胞在某一生物学过程中所处的不同阶段。例如，在细胞分化过程中，初始的未分化状态、不同分化路径中的中间状态，以及终末分化状态，都会被标记为不同的“state”。</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/1-2.png" alt="" class="img_ev3q"></p>
<p>Pseudotime时间：</p>
<p>这是算法模拟出来的一个时间轴，越接近0就说明越早</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/2-2.png" alt="" class="img_ev3q"></p>
<p>Seurat分群结果：</p>
<p>这其实就是之前用umap聚出来的为基准了，按其基因表达模式进行分类</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/3-2.png" alt="" class="img_ev3q"></p>
<p>细胞注释结果（前文没有注释，如果想要的话可以直接color_by=''labels''）</p>
<p>state状态分支（）</p>
<p>其实就是讲state状态分开来，更直观的看出各类处在什么分支上</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/4-2.png" alt="" class="img_ev3q"></p>
<p>在筛选完差异基因后，可以观察单个差异基因的表达情况。选择差异基因的原因的在整个分化过程中更加关键，能够揭示不同状态或分支间的生物学差异。</p>
<p>横轴代表拟时间，通常用来模拟细胞从一个初始状态到最终状态的进程；纵轴代表基因表达量，上面的位置表示在特定拟时间点上，基因的表达水平。</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/5-2.png" alt="" class="img_ev3q"></p>
<p>分支点设定在1的时候，表示关注在第一个分支点处的基因表达变化，细胞分类为3说明分为三个不同的簇。颜色通常表示基因的表达水平，颜色越深，表达越高；颜色越浅，表达越低。热图通过颜色变化来展示基因在不同细胞分支中的表达情况</p>
<p>这个热图用于展示在细胞分化过程中，不同分支上的基因表达模式。通过观察基因在分支上的表达差异，可以获得这些基因在不同细胞命运中的潜在角色，即哪些基因是上调的，哪些是下调的，从而反映基因表达的动态变化。</p>
<p><img decoding="async" loading="lazy" src="http://8.130.141.48/wp-content/uploads/2024/08/6-2.png" alt="" class="img_ev3q"></p>
<p>(图片分辨率或许有一些问题，自己画的时候可以调整一下width和height)</p>]]></content>
        <author>
            <name>zqqqj</name>
            <uri>https://github.com/zqqqqqqj1110</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics Informed Deep Learning (Part I):Data-driven Solutions of Nonlinear Partial Differential Equations]]></title>
        <id>https://your-docusaurus-test-site.com/blog/04-Physics-Informed-Deep-Learning-Part-one</id>
        <link href="https://your-docusaurus-test-site.com/blog/04-Physics-Informed-Deep-Learning-Part-one"/>
        <updated>2023-06-17T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[这是一篇关于使用数据驱动方法实现的 Physics-Informed Deep Learning（PINN）经典论文。]]></summary>
        <content type="html"><![CDATA[<p>这是一篇关于使用数据驱动方法实现的 Physics-Informed Deep Learning（PINN）经典论文。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="论文的来源">论文的来源<a href="https://your-docusaurus-test-site.com/blog/04-Physics-Informed-Deep-Learning-Part-one#%E8%AE%BA%E6%96%87%E7%9A%84%E6%9D%A5%E6%BA%90" class="hash-link" aria-label="Direct link to 论文的来源" title="Direct link to 论文的来源">​</a></h2>
<p>    首先，本人通过搜索很多 PINN 的论文，发现许多论文都在引用这篇论文，在好奇心的驱使下就在 google 学术上搜索了这篇论文，我们可以看到出现了两个版本，从标题名上看大致相同，作者也没变化。据开组会时，覃老师介绍说可能是因为前面这个版本是相当于没有正式发表还处于一个草稿阶段，后面那篇是经过整理并发表到了比较好的期刊中，我们可以从引用量(比较粗的<font color="red">红线</font>)以及 easyScholar (比较细的<font color="red">红线</font>)打上的标签还有作者希望我们引用这项工作的论文排名(作者更希望我们引用 2019 年正式分布的那篇)中看到区别，但不妨碍这几篇论文的优秀性，总的来说 M Raissi 等人的工作是非常出色的。</p>
<p><img decoding="async" loading="lazy" src="https://pic.imgdb.cn/item/649d31dc1ddac507cc30c3f0.jpg" alt="" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://pic.imgdb.cn/item/649d3c241ddac507cc427561.jpg" alt="" class="img_ev3q"></p>
<p>    他们也将这篇论文的工作产生的代码无私的奉献了出来，可以通过访问 Github 来查看相关代码，上面的代码是 tensorflow 的 1 版本写的，到现在 tensorflow 已经不支持 1 版本的 python 包安装，所以可能需要将上面的代码写成 2 版本的形式才能运行。 👉<a href="https://github.com/maziarraissi/PINNs" target="_blank" rel="noopener noreferrer">点我查看 Github 仓库</a></p>
<p><img decoding="async" loading="lazy" src="https://pic.imgdb.cn/item/649d37c91ddac507cc3a6e68.jpg" alt="" class="img_ev3q"></p>
<p>    这篇论文被视为数据驱动的 PINN 的研究工作的思想源头，有打算实现数据驱动的 PINN 工作的人可以先稍微熟悉该论文。他的论文分为三个部分，现在来介绍第一部分。<a href="https://arxiv.org/abs/1711.10561" target="_blank" rel="noopener noreferrer">原论文(Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations)</a></p>
<p>    想要明白 PINN，先从 PINN 是什么说起，PINN 其实是 Physics Informed Deep Learning 的缩写，中文中比较准确的翻译是<strong>物理信息深度学习</strong>，人话就是结合了物理信息的深度学习模型。</p>
<p>    其实将机器学习用在求解偏微分方程上不是什么难事，但是直接用肯定是不行的，主要面对了几个问题，只要能很好的解决以下问题，那问题就迎刃而解了。</p>
<ul>
<li>
<p>数据采集：数据采集的成本太高几乎无法实现，尤其是对小样本的数据样本，绝大多数的机器学习技术缺乏鲁棒性，无法提供任何收敛保证。</p>
</li>
<li>
<p>实际</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract摘要">Abstract（摘要）<a href="https://your-docusaurus-test-site.com/blog/04-Physics-Informed-Deep-Learning-Part-one#abstract%E6%91%98%E8%A6%81" class="hash-link" aria-label="Direct link to Abstract（摘要）" title="Direct link to Abstract（摘要）">​</a></h2>
<blockquote>
<p>    We introduce <em>physics informed neural networks</em>– neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial differential equations. In this two part treatise, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct classes of algorithms, namely continuous time and discrete time models. The resulting neural networks form a new class of data-efficient universal function approximators that naturally encode any underlying physical laws as prior information. In this first part, we demonstrate how these networks can be used to infer solutions to partial differential equations, and obtain physics-informed surrogate models that are fully differentiable with respect to all input coordinates and free parameters.</p>
</blockquote>
<p>    摘要的内容如上，建议多读几次，本笔记比较粗浅，有时间建议看看<a href="https://arxiv.org/abs/1711.10561" target="_blank" rel="noopener noreferrer">原文</a>。</p>
<p>    翻译成中文（deepl 翻译）：我们介绍了物理学上的神经网络 - 神经网络被训练来解决监督学习任务，同时尊重由一般非线性偏微分方程描述的任何特定的物理学规律。在这两部分论文中，我们介绍了我们在解决两类主要问题方面的发展：数据驱动的解决方案和数据驱动的偏微分方程的发现。根据可用数据的性质和安排，我们设计了两类不同的算法，即连续时间和离散时间模型。由此产生的神经网络形成了一类新的数据高效的通用函数近似器，自然地将任何潜在的物理规律编码为先验信息。在这第一部分，我们展示了这些网络如何被用来推断偏微分方程的解决方案，并获得物理信息的代用模型，这些模型对于所有输入坐标和自由参数是完全可微的。</p>]]></content>
        <author>
            <name>Tanger</name>
            <uri>https://github.com/redhat123456</uri>
        </author>
    </entry>
</feed>