<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">4 posts tagged with &quot;Machine Learn&quot; | 机器学习小纵队</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-test-site.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-test-site.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-test-site.com/blog/tags/machine-learn"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="4 posts tagged with &quot;Machine Learn&quot; | 机器学习小纵队"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-test-site.com/blog/tags/machine-learn"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/blog/tags/machine-learn" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-test-site.com/blog/tags/machine-learn" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="机器学习小纵队 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="机器学习小纵队 Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-K9P2+4+PNL1EfCT7eKZxLS9P9m1M9L3CwM2X7ZzZsda6CyaZozkn2lW7lRg3p2Ek" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.086be037.css">
<script src="/assets/js/runtime~main.d024a6ed.js" defer="defer"></script>
<script src="/assets/js/main.6b3632fc.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="机器学习小纵队" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/favicon.ico" alt="机器学习小纵队" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">机器学习小纵队</b></a><a class="navbar__item navbar__link" href="/docs/ch0/FEMATHS-wiki-introduction">计算数学以及机器学习Wiki</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">FEMATHS小组学习日志</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/FEMATHS" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/17-An_efficient_neural-network_and_finite-difference_hybrid_method_for_elliptic_interface_problems_with_applications">An efficient neural-network and finite-difference hybrid  method for elliptic interface problems with applications</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/16-A_new_analytical_formula_for_the_wave_equations_with_variable_coefficients">A new analytical formula for the wave equations with variable coefficients</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/15-Novel_and_general_discontinuity-removing_PINNs_for_elliptic_interface_problems">Novel and general discontinuity-removing PINNs for elliptic interface problems</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/14-DeepONet_Learning_nonlinear_operators_for_identifying">DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/13-Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backward Stochastic Differential Equations">Machine learning based spectral methods for partial differential equations</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/12-Related GANs and their SRGAN ablation experiments">Related GANs and their SRGAN ablation experiments</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/05-Automated and Context-Aware Repair of Color-Related Accessibility Issues for Android Apps">Automated and Context-Aware Repair of Color-Related Accessibility Issues for Android Apps</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/00-Ahead-of-our-research-efforts">欢迎来到FEMATHS小组学习日志</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/01-how-to-find-good-research-paper">从入门到入土？不，是精通！科技论文完全指南：如何找到一篇合适的科技论文</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/02-how-to-read-research-paper">从入门到入土？不，是精通！科技论文完全指南：如何正确且高效地阅读一篇科技论文</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/03-how-to-write-research-paper">从入门到入土？不，是精通！科技论文完全指南：如何写出一篇优秀的科技论文</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/06-Bioinformatic analysis1（Linux Operation Guide）">Bioinformatic analysis:linux操作指南之上游分析(Part 1)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/07-Bioinformatic analysis2（Quality control and clustering）">Bioinformatic analysis:质量控制与聚类分析(Part 2)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/08-Bioinformatic analysis3（Differential genes and cell labeling）">Bioinformatic analysis:差异基因与细胞标注(Part3)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/09-Bioinformatic analysis4（Enrichment analysis）">Bioinformatic analysis:富集分析 (Part4)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/10-Bioinformatic analysis5（PPI and FT Analysis）">Bioinformatic analysis:PPI分析(Part 5)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/11-Bioinformatic analysis6（Sequential analysis）">Bioinformatic analysis:拟时序分析(Part 6)</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/04-Physics-Informed-Deep-Learning-Part-one">Physics Informed Deep Learning (Part I) Data-driven  Solutions of Nonlinear Partial Differential Equations</a></li></ul></div></nav></aside><main class="col col--7"><header class="margin-bottom--xl"><h1>4 posts tagged with &quot;Machine Learn&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/blog/15-Novel_and_general_discontinuity-removing_PINNs_for_elliptic_interface_problems">Novel and general discontinuity-removing PINNs for elliptic interface problems</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2025-07-30T00:00:00.000Z">July 30, 2025</time> · <!-- -->25 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/57751257?v=4" alt="Tanger"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Tanger</span></a></div><small class="authorTitle_nd0D" title="Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model">Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model</small><div class="authorSocials_rSDt"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div class="markdown"><p>这是一篇关于处理变系数边界问题的 PINN 论文。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="摘要">摘要<a href="#摘要" class="hash-link" aria-label="Direct link to 摘要" title="Direct link to 摘要">​</a></h2>
<p><strong>摘要原文：</strong></p>
<p>This paper proposes a novel and general framework of the discontinuity-removing physicsinformed neural networks (DR-PINNs) for addressing elliptic interface problems. In the DR-PINNs, the solution is split into a smooth component and a non-smooth component, each represented by a separate network surrogate that can be trained either independently or together. The decoupling strategy involves training the two components sequentially. The first network handles the non-smooth part and pre-learns partial or full jumps to assist the second network in learning the complementary PDE conditions. Three decoupling strategies of handling interface problems are built by removing some jumps and incorporating cusp-capturing techniques. On the other hand, the decoupled approaches rely heavily on the cusp-enforced level-set function and are less efficient due to the need for two separate training stages. To overcome these limitations, a novel DR-PINN coupled approach is proposed in this work, where both components learn complementary conditions simultaneously in an integrated single network, eliminating the need for cusp-enforced level-set functions. Furthermore, the stability and accuracy of training are enhanced by an innovative architecture of the lightweight feedforward neural network (FNN) and a powerful geodesic acceleration Levenberg-Marquardt (gd-LM) optimizer. Several numerical experiments illustrate the effectiveness and great potential of the proposed method, with accuracy outperforming most deep neural network approaches and achieving the state-of-the-art results.</p>
<p><strong>摘要翻译：</strong></p>
<p>本文提出了一种新型且通用的断续性消除物理信息神经网络（DR-PINNs）框架，用于解决椭圆型界面问题。在 DR-PINNs 中，解被分解为光滑部分和非光滑部分，每个部分由独立的神经网络代理表示，这些代理可以单独训练或共同训练。解耦策略涉及依次训练这两个部分。第一个网络处理非光滑部分，并预先学习部分或全部跳跃，以协助第二个网络学习互补的偏微分方程（PDE）条件。通过去除部分跳跃并结合尖点捕获技术，构建了三种处理界面问题的解耦策略。另一方面，解耦方法高度依赖于尖点强制水平集函数，且由于需要两个独立的训练阶段而效率较低。为克服这些局限性，本文提出了一种新型 DR-PINN 耦合方法，其中两个组件在集成单一网络中同时学习互补条件，消除了对尖点强制水平集函数的需求。此外，通过轻量级前馈神经网络（FNN）的创新架构和强大的几何加速 Levenberg-Marquardt（gd-LM）优化器，训练的稳定性和准确性得到提升。多个数值实验验证了所提方法的有效性和巨大潜力，其精度显著优于现有方法。</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/pinn">PINN</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learn">Machine Learn</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/elliptic-interface-problems">Elliptic interface problems</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/thesis-study-notes">Thesis Study Notes</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Novel and general discontinuity-removing PINNs for elliptic interface problems" href="/blog/15-Novel_and_general_discontinuity-removing_PINNs_for_elliptic_interface_problems"><b>Read more</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/blog/14-DeepONet_Learning_nonlinear_operators_for_identifying">DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2025-07-16T00:00:00.000Z">July 16, 2025</time> · <!-- -->16 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/57751257?v=4" alt="Tanger"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Tanger</span></a></div><small class="authorTitle_nd0D" title="Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model">Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model</small><div class="authorSocials_rSDt"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div class="markdown"><p>这是一篇开山之作提出了一个深度学习框架 DeepONet 用于求解偏微分方程的求解器，这篇论文介绍了原理。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="摘要">摘要<a href="#摘要" class="hash-link" aria-label="Direct link to 摘要" title="Direct link to 摘要">​</a></h2>
<p><strong>摘要原文：</strong></p>
<p>While it is widely known that neural networks are universal approximators of continuous functions, a less known and perhaps more powerful result is that a neural network with a single hidden layer can approximate accurately any nonlinear continuous operator [5]. This universal approximation theorem is suggestive of the potential application of neural networks in learning nonlinear operators from data. However, the theorem guarantees only a small approximation error for a sufficient large network, and does not consider the important optimization and generalization errors. To realize this theorem in practice, we propose deep operator networks (DeepONets) to learn operators accurately and efficiently from a relatively small dataset. A DeepONet consists of two sub-networks, one for encoding the input function at a fixed number of sensors <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">x_i = 1, ... , m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">m</span></span></span></span> (branch net), and another for encoding the locations for the output functions (trunk net). We perform systematic simulations for identifying two types of operators, i.e., dynamic systems and partial differential equations, and demonstrate that DeepONet significantly reduces the generalization error compared to the fully-connected networks. We also derive theoretically the dependence of the approximation error in terms of the number of sensors (where the input function is defined) as well as the input function type, and we verify the theorem with computational results. More importantly, we observe high-order error convergence in our computational tests, namely polynomial rates (from half order to fourth order) and even exponential convergence with respect to the training dataset size.</p>
<p><strong>摘要翻译：</strong></p>
<p>尽管神经网络是连续函数的通用逼近器这一事实广为人知，但一个较少为人所知且可能更强大的结果是：具有单个隐藏层的神经网络能够精确逼近任何<strong>非线性连续算子</strong>。这一通用<strong>逼近定理</strong>暗示了神经网络在从数据中学习非线性算子方面的潜在应用。然而，该定理仅保证在网络规模足够大时存在较小的逼近误差，并未考虑重要的优化误差和泛化误差。为了在实践中实现这一定理，我们提出**深度算子网络（DeepONets）**以从相对较小的数据集准确高效地学习算子。<strong>一个 DeepONet 由两个子网络组成：一个用于在固定数量的传感器上编码输入函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">x_i = 1, ..., m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">m</span></span></span></span>（分支网络），另一个用于编码输出函数的位置（主干网络）</strong>。我们通过系统性模拟识别两种类型的算子，即动态系统和偏微分方程，并证明 DeepONet 相较于全连接网络显著降低了泛化误差。我们还从理论上推导了近似误差与传感器数量（即输入函数定义的传感器数量）以及输入函数类型之间的依赖关系，并通过计算结果验证了该定理。更重要的是，我们在计算测试中观察到高阶误差收敛，即多项式收敛率（从半阶到四阶）甚至与训练数据集大小相关的指数收敛。</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/pinn">PINN</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learn">Machine Learn</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/spectral-methods">spectral methods</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/thesis-study-notes">Thesis Study Notes</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators" href="/blog/14-DeepONet_Learning_nonlinear_operators_for_identifying"><b>Read more</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/blog/13-Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backward Stochastic Differential Equations">Machine learning based spectral methods for partial differential equations</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2025-07-15T00:00:00.000Z">July 15, 2025</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/57751257?v=4" alt="Tanger"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Tanger</span></a></div><small class="authorTitle_nd0D" title="Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model">Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model</small><div class="authorSocials_rSDt"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div class="markdown"><p>这是一篇使用谱元方法与 PINN（物理信息神经网络）相结合的论文。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="摘要">摘要<a href="#摘要" class="hash-link" aria-label="Direct link to 摘要" title="Direct link to 摘要">​</a></h2>
<p><strong>摘要原文：</strong></p>
<p>Spectral methods are an important part of scientific computing’s arsenal for solving partial differential equations (PDEs). However, their applicability and effectiveness depend crucially on the choice of basis functions used to expand the solution of a PDE. The last decade has seen the emergence of deep learning as a strong contender in providing efficient representations of complex functions. In the current work, we present an approach for combining deep neural networks with spectral methods to solve PDEs. In particular, we use a deep learning technique known as the Deep Operator Network (DeepONet) to identify candidate functions on which to expand the solution of PDEs. We have devised an approach that uses the candidate functions provided by the DeepONet as a starting point to construct a set of functions that have the following properties: (1) they constitute a basis, (2) they are orthonormal, and (3) they are hierarchical, i.e., akin to Fourier series or orthogonal polynomials. We have exploited the favorable properties of our custom-made basis functions to both study their approximation capability and use them to expand the solution of linear and nonlinear time-dependent PDEs. The proposed approach advances the state of the art and versatility of spectral methods and, more generally, promotes the synergy between traditional scientific computing and machine learning.</p>
<p><strong>摘要翻译：</strong></p>
<p>谱方法是科学计算用于求解偏微分方程 (PDE) 的重要工具。然而，它们的适用性和有效性在很大程度上取决于用于扩展偏微分方程解的基函数的选择。近十年来，深度学习异军突起，成为提供复杂函数高效表示的有力竞争者。在当前的工作中，我们提出了一种将深度神经网络与光谱方法相结合来求解 PDE 的方法。特别是，我们使用一种被称为深度算子网络（DeepONet）的深度学习技术来识别候选函数，并在此基础上扩展 PDE 的求解。我们设计了一种方法，以 DeepONet 提供的候选函数为起点，构建一组具有以下特性的函数：(1) 它们构成一个基础；(2) 它们是正交的；(3) 它们是分层的，即类似于傅里叶级数或正交多项式。我们利用定制基函数的有利特性，研究了它们的近似能力，并利用它们扩展了线性和非线性时变 PDE 的解。所提出的方法推进了频谱方法的技术水平和多功能性，更广泛地说，促进了传统科学计算与机器学习之间的协同作用。</p>
<p>其实只要细读了他的摘要就可以发现这篇论文的做法比较独特，他并不是把机器学习与谱方法相融合，而是采取了一种分阶段的模式，第一步是使用 DeepONet 去识别候选函数，再利用常规的谱方法来完成剩下的计算工作，他并不是一整块的模型而是耦合度低的分阶段模型。这种思想其实结合误差达到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span> 就能够理解，不过也算是给机器学习融合谱方法提供了一种思路，接下来我们详细的阅读这篇文章的结果以及方法。</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/pinn">PINN</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learn">Machine Learn</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/spectral-methods">spectral methods</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/paper-study-notes">Paper Study Notes</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Machine learning based spectral methods for partial differential equations" href="/blog/13-Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backward Stochastic Differential Equations"><b>Read more</b></a></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/blog/04-Physics-Informed-Deep-Learning-Part-one">Physics Informed Deep Learning (Part I) Data-driven  Solutions of Nonlinear Partial Differential Equations</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-06-17T00:00:00.000Z">June 17, 2023</time> · <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/57751257?v=4" alt="Tanger"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Tanger</span></a></div><small class="authorTitle_nd0D" title="Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model">Academic rubbish | CV Engineers | Visual bubble | compute math | PINN | Mathematical model</small><div class="authorSocials_rSDt"><a href="https://github.com/redhat123456" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 256 250" preserveAspectRatio="xMidYMid" style="--dark:#000;--light:#fff" class="authorSocialLink_owbf githubSvg_Uu4N"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div class="markdown"><p>这是一篇关于使用数据驱动方法实现的 Physics-Informed Deep Learning（PINN）经典论文。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="论文的来源">论文的来源<a href="#论文的来源" class="hash-link" aria-label="Direct link to 论文的来源" title="Direct link to 论文的来源">​</a></h2>
<p>    首先，本人通过搜索很多 PINN 的论文，发现许多论文都在引用这篇论文，在好奇心的驱使下就在 google 学术上搜索了这篇论文，我们可以看到出现了两个版本，从标题名上看大致相同，作者也没变化。据开组会时，覃老师介绍说可能是因为前面这个版本是相当于没有正式发表还处于一个草稿阶段，后面那篇是经过整理并发表到了比较好的期刊中，我们可以从引用量(比较粗的<font color="red">红线</font>)以及 easyScholar (比较细的<font color="red">红线</font>)打上的标签还有作者希望我们引用这项工作的论文排名(作者更希望我们引用 2019 年正式分布的那篇)中看到区别，但不妨碍这几篇论文的优秀性，总的来说 M Raissi 等人的工作是非常出色的。</p>
<p><img decoding="async" loading="lazy" src="https://pic.imgdb.cn/item/649d31dc1ddac507cc30c3f0.jpg" alt="" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://pic.imgdb.cn/item/649d3c241ddac507cc427561.jpg" alt="" class="img_ev3q"></p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/pinn">PINN</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learn">Machine Learn</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/thesis-study-notes">Thesis Study Notes</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Physics Informed Deep Learning (Part I) Data-driven  Solutions of Nonlinear Partial Differential Equations" href="/blog/04-Physics-Informed-Deep-Learning-Part-one"><b>Read more</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">文档</h4></div><div class="col footer__col"><h4 class="footer__title">社区</h4><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow</a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">更多</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/FEMATHS" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>